{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOcCh7YQKaO1fJxDqhMbeMQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2d42cc549c4a46cc9921c0ec5b73c401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3531977bbc7c4c668a6e8defa2965cb3",
              "IPY_MODEL_9370cdefc9ee44dab0fdb8bc0c610725",
              "IPY_MODEL_673c0e63069844b491369ad062213de2"
            ],
            "layout": "IPY_MODEL_d01817d24372455aac19d2352a20ada9"
          }
        },
        "3531977bbc7c4c668a6e8defa2965cb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c55abcc9b7e84df1b26c928333c8285b",
            "placeholder": "​",
            "style": "IPY_MODEL_3ccdbc45a2ac41e4b51f1a496a6564bb",
            "value": "config.json: 100%"
          }
        },
        "9370cdefc9ee44dab0fdb8bc0c610725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4902f328d98f478a955b4195eeb1a5bd",
            "max": 660,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ad6b9056212475ba3477f57c7a22fa9",
            "value": 660
          }
        },
        "673c0e63069844b491369ad062213de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be93d69ef38548c1ae284c2aff13bff2",
            "placeholder": "​",
            "style": "IPY_MODEL_562cf951a39e46ed873c1382c0da2b97",
            "value": " 660/660 [00:00&lt;00:00, 16.9kB/s]"
          }
        },
        "d01817d24372455aac19d2352a20ada9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c55abcc9b7e84df1b26c928333c8285b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ccdbc45a2ac41e4b51f1a496a6564bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4902f328d98f478a955b4195eeb1a5bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ad6b9056212475ba3477f57c7a22fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be93d69ef38548c1ae284c2aff13bff2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "562cf951a39e46ed873c1382c0da2b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "820264867bb3425885fef92f8c74907e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d29a3aeb05846d492454926a675f023",
              "IPY_MODEL_76f4446bc3e7467dba827d9a898e5c45",
              "IPY_MODEL_b63dbf05679744c59750d8d1577324d6"
            ],
            "layout": "IPY_MODEL_4af07581a5af4c199a54c58dd6ebacca"
          }
        },
        "5d29a3aeb05846d492454926a675f023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eeb713214c0549a4938d44d84eff50fd",
            "placeholder": "​",
            "style": "IPY_MODEL_9c12a8a6973045a6a190a1837d444a0d",
            "value": "modeling_esm_plusplus.py: 100%"
          }
        },
        "76f4446bc3e7467dba827d9a898e5c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5944df1f1934f2abde147c0043cf00a",
            "max": 42125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f805f5b1f3ed4582850dc656df1a659c",
            "value": 42125
          }
        },
        "b63dbf05679744c59750d8d1577324d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6027ebebb5894d96bc13ef6b6437df22",
            "placeholder": "​",
            "style": "IPY_MODEL_d46a40acde3a4bf7b67e6aa8dd5b7362",
            "value": " 42.1k/42.1k [00:00&lt;00:00, 885kB/s]"
          }
        },
        "4af07581a5af4c199a54c58dd6ebacca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeb713214c0549a4938d44d84eff50fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c12a8a6973045a6a190a1837d444a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5944df1f1934f2abde147c0043cf00a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f805f5b1f3ed4582850dc656df1a659c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6027ebebb5894d96bc13ef6b6437df22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d46a40acde3a4bf7b67e6aa8dd5b7362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bae510b5c18e4b908ed94b9a9ffbced6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_baccbf275b95457e840ed1123c1be96e",
              "IPY_MODEL_a4ec381381094f58af0d7fed8af0ca61",
              "IPY_MODEL_7511cbd8bfbc4e868ebd82e5f7d5faf0"
            ],
            "layout": "IPY_MODEL_79bea9e802b044aebbb36fb6dcbc661a"
          }
        },
        "baccbf275b95457e840ed1123c1be96e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b47d273a1d949849042fdbf016a6bbe",
            "placeholder": "​",
            "style": "IPY_MODEL_fdcf2728a3da470081e743f07ff7e60f",
            "value": "model.safetensors: 100%"
          }
        },
        "a4ec381381094f58af0d7fed8af0ca61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66ac22e522f449428d0214c9b97b205d",
            "max": 2300189544,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10c9e97f34ba463fa7769434582ff60a",
            "value": 2300189544
          }
        },
        "7511cbd8bfbc4e868ebd82e5f7d5faf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_934df197a02b428c8ef06a79db87b0eb",
            "placeholder": "​",
            "style": "IPY_MODEL_72903e5979584010825dc4a6b5277188",
            "value": " 2.30G/2.30G [00:54&lt;00:00, 42.4MB/s]"
          }
        },
        "79bea9e802b044aebbb36fb6dcbc661a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b47d273a1d949849042fdbf016a6bbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdcf2728a3da470081e743f07ff7e60f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66ac22e522f449428d0214c9b97b205d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10c9e97f34ba463fa7769434582ff60a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "934df197a02b428c8ef06a79db87b0eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72903e5979584010825dc4a6b5277188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1448f6baea844fe8b9661de310b1d066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e32be594ac0f49eeb24f1b5fdbffa1ba",
              "IPY_MODEL_55ccfc9b31d6422b965d1611c90504e1",
              "IPY_MODEL_da34ca4c86d540d48eee3cd32ba4d58e"
            ],
            "layout": "IPY_MODEL_3be98ad90599418abe56702726d9e949"
          }
        },
        "e32be594ac0f49eeb24f1b5fdbffa1ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25b89338b6734809be541eccb2fa24a9",
            "placeholder": "​",
            "style": "IPY_MODEL_3039658222fe446abc4e8182dd2571ce",
            "value": "Downloading builder script: 100%"
          }
        },
        "55ccfc9b31d6422b965d1611c90504e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0458211af08d45e787543759b3b6a619",
            "max": 4203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d2a03f544a54d4cb32774968ec9b7c3",
            "value": 4203
          }
        },
        "da34ca4c86d540d48eee3cd32ba4d58e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2feef36633e9474697d1a66af54f5f74",
            "placeholder": "​",
            "style": "IPY_MODEL_848f52e9f5424af7be7eadecf538ace9",
            "value": " 4.20k/4.20k [00:00&lt;00:00, 522kB/s]"
          }
        },
        "3be98ad90599418abe56702726d9e949": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25b89338b6734809be541eccb2fa24a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3039658222fe446abc4e8182dd2571ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0458211af08d45e787543759b3b6a619": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d2a03f544a54d4cb32774968ec9b7c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2feef36633e9474697d1a66af54f5f74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "848f52e9f5424af7be7eadecf538ace9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3df08a394fad46efa401087530d00e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4371f8aaef2c40009c6fdf17e1163eae",
              "IPY_MODEL_81e7fd696714413c97e8b934d8255cd5",
              "IPY_MODEL_d97c4976c758471995668dd1fb25bc5a"
            ],
            "layout": "IPY_MODEL_e111f9155071484d9d5b4c9be08843cf"
          }
        },
        "4371f8aaef2c40009c6fdf17e1163eae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5245a6a0c4554ab594c24ae344fe9e5f",
            "placeholder": "​",
            "style": "IPY_MODEL_c148645823ba4663b99a19c799e09e79",
            "value": "100%"
          }
        },
        "81e7fd696714413c97e8b934d8255cd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07a58255401841a89dd47e46678e7546",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc7d938c4fce4d65a5495aecf483976f",
            "value": 4
          }
        },
        "d97c4976c758471995668dd1fb25bc5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3acfabcb803e4623b8aef12073f6225b",
            "placeholder": "​",
            "style": "IPY_MODEL_6f22f364bfaf42599f890d4496ac7a38",
            "value": " 4/4 [00:05&lt;00:00,  1.01s/it]"
          }
        },
        "e111f9155071484d9d5b4c9be08843cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5245a6a0c4554ab594c24ae344fe9e5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c148645823ba4663b99a19c799e09e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07a58255401841a89dd47e46678e7546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc7d938c4fce4d65a5495aecf483976f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3acfabcb803e4623b8aef12073f6225b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f22f364bfaf42599f890d4496ac7a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c649d54d77554ca7a862243915cff823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76625b4020f44758b00c4402f0323db2",
              "IPY_MODEL_30b38360b1ed4c99b7bf37e89c6c74fe",
              "IPY_MODEL_351c4c4fcc5d423ba1902ab620b0b9f5"
            ],
            "layout": "IPY_MODEL_e0cdd2463bc3400f8c28a578d5905828"
          }
        },
        "76625b4020f44758b00c4402f0323db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_318c3e3a29c14390afa253c67a6873b6",
            "placeholder": "​",
            "style": "IPY_MODEL_93de9f6115f5478c969bcf5aab3767a5",
            "value": "100%"
          }
        },
        "30b38360b1ed4c99b7bf37e89c6c74fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f26474b04ca430ebe6cca12176805bd",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbd0914a0dff483ebb173f3e513693a7",
            "value": 22
          }
        },
        "351c4c4fcc5d423ba1902ab620b0b9f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28660e0f8e304486a87efd186b430e83",
            "placeholder": "​",
            "style": "IPY_MODEL_76b53cd9b0f344afb8eb5c3abda183d7",
            "value": " 22/22 [00:31&lt;00:00,  1.41s/it]"
          }
        },
        "e0cdd2463bc3400f8c28a578d5905828": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "318c3e3a29c14390afa253c67a6873b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93de9f6115f5478c969bcf5aab3767a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f26474b04ca430ebe6cca12176805bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbd0914a0dff483ebb173f3e513693a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28660e0f8e304486a87efd186b430e83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76b53cd9b0f344afb8eb5c3abda183d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VadimDu/Protein_LLM_modeling/blob/main/clean_ver_Modeling_ESM_plusplus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling Synthyra/ESMplusplus_large protein LLM\n",
        "ESM-plus-plus is a more effienct and Huggingface-compatibile implementation of the new ESM3 (ESM-C)LLM for protein embeddings.\n",
        "\n",
        "The cells below will be implemented via HuggingFace libraries and advanced wrapper scripts of the latest ESM models, inc. the newly relased ESM3 (ESM-C).\n",
        "\n",
        "The code and models below are obtained from [HuggingFace/Synthyra/ESMplusplus_large](https://huggingface.co/Synthyra/ESMplusplus_large) repo, which corresponds to the large version of 600 million parameter ESM-C model.\n",
        "\n",
        "ESM++ is a faithful implementation of ESMC (license) that allows for batching and standard Huggingface compatibility without requiring the ESM Python package.\n",
        "\n",
        "According to the authors this 600M parameter ESM-C model rivals the 3B parameter ESM2 and approaches the capabilities of the 15B model, delivering frontier performance with far greater efficiency (in terms of computational speed  & resources)."
      ],
      "metadata": {
        "id": "N0ig7KP8Fm8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below is obtain from [modeling_esm_plusplus.py](https://huggingface.co/Synthyra/ESMplusplus_large/blob/main/modeling_esm_plusplus.py) that suppose to be a general code for various downstream supervised classification tasks."
      ],
      "metadata": {
        "id": "6o5ZEmbLGrB4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and env. variables"
      ],
      "metadata": {
        "id": "B0xCdz9pHKOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "ESM++ model implementation.\n",
        "\n",
        "ESM++ is a faithful implementation of ESMC that allows for batching and standard Huggingface compatibility\n",
        "The ESM Python package is not required\n",
        "\n",
        "Modified from https://github.com/evolutionaryscale/esm\n",
        "License: https://www.evolutionaryscale.ai/policies/cambrian-non-commercial-license-agreement\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dataclasses import dataclass\n",
        "from functools import cache, partial\n",
        "from pathlib import Path\n",
        "from typing import Optional, Tuple, Union\n",
        "from einops import rearrange, repeat\n",
        "from huggingface_hub import snapshot_download\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.processors import TemplateProcessing\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import PreTrainedModel, PreTrainedTokenizerFast, PretrainedConfig\n",
        "from transformers.modeling_outputs import ModelOutput"
      ],
      "metadata": {
        "id": "u7ppcQk3GqNp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration class for ESM++ model, multi-head with rotary position embeddings, transformer & ffn layers, output types"
      ],
      "metadata": {
        "id": "tXE5ljC9Djxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ESMplusplusConfig(PretrainedConfig):\n",
        "    \"\"\"Configuration class for ESM++ model.\n",
        "\n",
        "    Args:\n",
        "        vocab_size: Size of the vocabulary\n",
        "        hidden_size: Dimension of hidden layers\n",
        "        num_attention_heads: Number of attention heads\n",
        "        num_hidden_layers: Number of transformer layers\n",
        "        num_labels: Number of output labels for classification\n",
        "        problem_type: Type of problem - regression, single/multi label classification\n",
        "    \"\"\"\n",
        "    model_type = \"ESMplusplus\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size: int = 64,\n",
        "        hidden_size: int = 960,\n",
        "        num_attention_heads: int = 15,\n",
        "        num_hidden_layers: int = 30,\n",
        "        num_labels: int = 2,\n",
        "        problem_type: str | None = None,\n",
        "        dropout: float = 0.0,\n",
        "        initializer_range: float = 0.02,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.num_hidden_layers = num_hidden_layers\n",
        "        self.num_labels = num_labels\n",
        "        self.problem_type = problem_type\n",
        "        self.dropout = dropout\n",
        "        self.initializer_range = initializer_range\n",
        "\n",
        "\n",
        "### Rotary Embeddings\n",
        "def rotate_half(x: torch.Tensor, interleaved: bool = False) -> torch.Tensor:\n",
        "    \"\"\"Rotates half the hidden dims of the input.\"\"\"\n",
        "    if not interleaved:\n",
        "        x1, x2 = x.chunk(2, dim=-1)\n",
        "        return torch.cat((-x2, x1), dim=-1)\n",
        "    else:\n",
        "        x1, x2 = x[..., ::2], x[..., 1::2]\n",
        "        return rearrange(\n",
        "            torch.stack((-x2, x1), dim=-1), \"... d two -> ... (d two)\", two=2\n",
        "        )\n",
        "\n",
        "\n",
        "def apply_rotary_emb_torch(\n",
        "    x: torch.Tensor,\n",
        "    cos: torch.Tensor,\n",
        "    sin: torch.Tensor,\n",
        "    interleaved: bool = False,\n",
        "    _inplace: bool = False,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Apply rotary embeddings to input based on cos and sin.\"\"\"\n",
        "    ro_dim = cos.shape[-1] * 2\n",
        "    assert ro_dim <= x.shape[-1]\n",
        "    seqlen = x.size(1)\n",
        "    cos = cos[:seqlen]\n",
        "    sin = sin[:seqlen]\n",
        "    cos = repeat(cos, \"s d -> s 1 (2 d)\")\n",
        "    sin = repeat(sin, \"s d -> s 1 (2 d)\")\n",
        "    return torch.cat(\n",
        "        [\n",
        "            x[..., :ro_dim] * cos + rotate_half(x[..., :ro_dim], interleaved) * sin,\n",
        "            x[..., ro_dim:],\n",
        "        ],\n",
        "        dim=-1,\n",
        "    )\n",
        "\n",
        "\n",
        "class RotaryEmbedding(torch.nn.Module):\n",
        "    \"\"\"Rotary position embeddings.\n",
        "\n",
        "    Based on the paper \"RoFormer: Enhanced Transformer with Rotary Position Embedding\"\n",
        "\n",
        "    Args:\n",
        "        dim: Dimension of the embedding\n",
        "        base: Base for computing angular frequencies\n",
        "        interleaved: Whether to use interleaved rotations\n",
        "        scale_base: Base for scaling\n",
        "        scaling_factor: Factor for scaling positions\n",
        "        pos_idx_in_fp32: Whether to compute position indices in fp32\n",
        "        device: Computation device\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim: int,\n",
        "        base: float = 10000.0,\n",
        "        interleaved: bool = False,\n",
        "        scale_base: Optional[float] = None,\n",
        "        scaling_factor: float = 1.0,\n",
        "        pos_idx_in_fp32: bool = True,\n",
        "        device: Optional[torch.device] = None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.base = float(base)\n",
        "        self.pos_idx_in_fp32 = pos_idx_in_fp32\n",
        "        self.interleaved = interleaved\n",
        "        self.scale_base = scale_base\n",
        "        self.scaling_factor = scaling_factor\n",
        "        self.device = device\n",
        "\n",
        "        self._seq_len_cached = 0\n",
        "        self._cos_cached = None\n",
        "        self._sin_cached = None\n",
        "        self._cos_k_cached = None\n",
        "        self._sin_k_cached = None\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        \"\"\"Reset the parameters of the embedding.\"\"\"\n",
        "        inv_freq = self._compute_inv_freq(self.device)\n",
        "        self.register_buffer(\"inv_freq\", inv_freq, persistent=False)\n",
        "        arange = torch.arange(0, self.dim, 2, device=self.device, dtype=torch.float32)\n",
        "        scale = (\n",
        "            (arange + 0.4 * self.dim) / (1.4 * self.dim)\n",
        "            if self.scale_base is not None\n",
        "            else None\n",
        "        )\n",
        "        self.register_buffer(\"scale\", scale)\n",
        "\n",
        "    def _compute_inv_freq(self, device: Optional[torch.device] = None) -> torch.Tensor:\n",
        "        \"\"\"Compute inverse frequency bands.\"\"\"\n",
        "        return 1 / (\n",
        "            self.base\n",
        "            ** (\n",
        "                torch.arange(0, self.dim, 2, device=device, dtype=torch.float32)\n",
        "                / self.dim\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def _update_cos_sin_cache(self, seqlen: int, device: Optional[torch.device] = None, dtype: Optional[torch.dtype] = None):\n",
        "        \"\"\"Update the cached cosine and sine values.\"\"\"\n",
        "        if (\n",
        "            seqlen > self._seq_len_cached\n",
        "            or self._cos_cached is None\n",
        "            or self._cos_cached.device != device\n",
        "            or self._cos_cached.dtype != dtype\n",
        "            or (self.training and self._cos_cached.is_inference())\n",
        "        ):\n",
        "            self._seq_len_cached = seqlen\n",
        "            if self.pos_idx_in_fp32:\n",
        "                t = torch.arange(seqlen, device=device, dtype=torch.float32)\n",
        "                t /= self.scaling_factor\n",
        "                if self.inv_freq.dtype != torch.float32:\n",
        "                    inv_freq = self.inv_freq.to(torch.float32)\n",
        "                else:\n",
        "                    inv_freq = self.inv_freq\n",
        "            else:\n",
        "                t = torch.arange(seqlen, device=device, dtype=self.inv_freq.dtype)\n",
        "                t /= self.scaling_factor\n",
        "                inv_freq = self.inv_freq\n",
        "            freqs = torch.outer(t, inv_freq)\n",
        "\n",
        "            if self.scale is None:\n",
        "                self._cos_cached = torch.cos(freqs).to(dtype)\n",
        "                self._sin_cached = torch.sin(freqs).to(dtype)\n",
        "            else:\n",
        "                power = (\n",
        "                    torch.arange(\n",
        "                        seqlen, dtype=self.scale.dtype, device=self.scale.device\n",
        "                    )\n",
        "                    - seqlen // 2\n",
        "                ) / self.scale_base\n",
        "                scale = self.scale.to(device=power.device) ** power.unsqueeze(-1)\n",
        "                self._cos_cached = (torch.cos(freqs) * scale).to(dtype)\n",
        "                self._sin_cached = (torch.sin(freqs) * scale).to(dtype)\n",
        "                self._cos_k_cached = (torch.cos(freqs) / scale).to(dtype)\n",
        "                self._sin_k_cached = (torch.sin(freqs) / scale).to(dtype)\n",
        "\n",
        "    def forward(self, q: torch.Tensor, k: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"Apply rotary embeddings to queries and keys.\n",
        "\n",
        "        Args:\n",
        "            q: Query tensor of shape (batch, seqlen, nheads, headdim)\n",
        "            k: Key tensor of shape (batch, seqlen, nheads, headdim)\n",
        "\n",
        "        Returns:\n",
        "            Tuple of rotated query and key tensors\n",
        "        \"\"\"\n",
        "        self._update_cos_sin_cache(q.shape[1], device=q.device, dtype=q.dtype)\n",
        "        assert self._cos_cached is not None\n",
        "        assert self._sin_cached is not None\n",
        "        if self.scale is None:\n",
        "            return (\n",
        "                apply_rotary_emb_torch(\n",
        "                    q,\n",
        "                    self._cos_cached,\n",
        "                    self._sin_cached,\n",
        "                    self.interleaved,\n",
        "                    True,  # inplace=True\n",
        "                ),\n",
        "                apply_rotary_emb_torch(\n",
        "                    k,\n",
        "                    self._cos_cached,\n",
        "                    self._sin_cached,\n",
        "                    self.interleaved,\n",
        "                    True,  # inplace=True\n",
        "                ),\n",
        "            )  # type: ignore\n",
        "        else:\n",
        "            assert False\n",
        "\n",
        "\n",
        "### Feedforward Network Components\n",
        "def swiglu_correction_fn(expansion_ratio: float, d_model: int) -> int:\n",
        "    \"\"\"Compute corrected dimension for SwiGLU.\"\"\"\n",
        "    return int(((expansion_ratio * d_model) + 255) // 256 * 256)\n",
        "\n",
        "\n",
        "class SwiGLU(nn.Module):\n",
        "    \"\"\"SwiGLU activation function.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(SwiGLU, self).__init__()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x1, x2 = x.chunk(2, dim=-1)\n",
        "        return F.silu(x1) * x2\n",
        "\n",
        "\n",
        "def swiglu_ln_ffn(d_model: int, expansion_ratio: float) -> nn.Sequential:\n",
        "    \"\"\"Create SwiGLU feedforward network with layer normalization.\"\"\"\n",
        "    return nn.Sequential(\n",
        "        nn.LayerNorm(d_model),\n",
        "        nn.Linear(\n",
        "            d_model, swiglu_correction_fn(expansion_ratio, d_model) * 2, bias=False\n",
        "        ),\n",
        "        SwiGLU(),\n",
        "        nn.Linear(swiglu_correction_fn(expansion_ratio, d_model), d_model, bias=False),\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "### Transformer block with attention and feedforward layers\n",
        "class UnifiedTransformerBlock(nn.Module):\n",
        "    \"\"\"Transformer block with attention and feedforward layers.\n",
        "\n",
        "    Args:\n",
        "        d_model: Model dimension\n",
        "        n_heads: Number of attention heads\n",
        "        residue_scaling_factor: Factor for scaling residual connections\n",
        "        expansion_ratio: Expansion ratio for feedforward network\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        d_model: int,\n",
        "        n_heads: int,\n",
        "        residue_scaling_factor: float = 1,\n",
        "        expansion_ratio: float = 8 / 3,\n",
        "        dropout: float = 0.0,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.attn = MultiHeadAttention(d_model, n_heads)\n",
        "        self.ffn = swiglu_ln_ffn(d_model, expansion_ratio)\n",
        "        self.scaling_factor = residue_scaling_factor\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x: torch.Tensor,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        output_attentions: bool = False,\n",
        "    ) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor\n",
        "            attention_mask: Optional attention mask\n",
        "            output_attentions: Whether to return attention weights\n",
        "\n",
        "        Returns:\n",
        "            Output tensor after transformer block, and optionally attention weights\n",
        "        \"\"\"\n",
        "        attn_output, attn_weights = self.attn(x, attention_mask, output_attentions)\n",
        "        x = x + self.dropout(attn_output) / self.scaling_factor\n",
        "        x = x + self.dropout(self.ffn(x)) / self.scaling_factor\n",
        "        return x, attn_weights\n",
        "\n",
        "\n",
        "### Multi-head attention with rotary embeddings\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"Multi-head attention with rotary embeddings.\n",
        "\n",
        "    Args:\n",
        "        d_model: Model dimension\n",
        "        n_heads: Number of attention heads\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model: int, n_heads: int):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_head = self.d_model // self.n_heads\n",
        "        self.layernorm_qkv = nn.Sequential(\n",
        "            nn.LayerNorm(d_model), nn.Linear(d_model, d_model * 3, bias=False)\n",
        "        )\n",
        "        self.out_proj = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.q_ln = nn.LayerNorm(d_model, bias=False)\n",
        "        self.k_ln = nn.LayerNorm(d_model, bias=False)\n",
        "        self.reshaper = partial(rearrange, pattern=\"b s (h d) -> b h s d\", h=n_heads)\n",
        "        self.rotary = RotaryEmbedding(d_model // n_heads)\n",
        "\n",
        "    def _apply_rotary(self, q: torch.Tensor, k: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"Apply rotary embeddings to query and key.\"\"\"\n",
        "        q = q.unflatten(-1, (self.n_heads, self.d_head))\n",
        "        k = k.unflatten(-1, (self.n_heads, self.d_head))\n",
        "        q, k = self.rotary(q, k)\n",
        "        q = q.flatten(-2, -1)\n",
        "        k = k.flatten(-2, -1)\n",
        "        return q, k\n",
        "\n",
        "    def forward(self, x: torch.Tensor, attention_mask: Optional[torch.Tensor] = None, output_attentions: bool = False) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor\n",
        "            attention_mask: Optional attention mask\n",
        "            output_attentions: Whether to return attention weights\n",
        "\n",
        "        Returns:\n",
        "            Output tensor after self attention, and optionally attention weights\n",
        "        \"\"\"\n",
        "        attn_weights = None\n",
        "        qkv_BLD3 = self.layernorm_qkv(x)\n",
        "        query_BLD, key_BLD, value_BLD = torch.chunk(qkv_BLD3, 3, dim=-1)\n",
        "        query_BLD, key_BLD = (\n",
        "            self.q_ln(query_BLD).to(query_BLD.dtype),\n",
        "            self.k_ln(key_BLD).to(query_BLD.dtype),\n",
        "        )\n",
        "        query_BLD, key_BLD = self._apply_rotary(query_BLD, key_BLD)\n",
        "        query_BHLD, key_BHLD, value_BHLD = map(self.reshaper, (query_BLD, key_BLD, value_BLD))\n",
        "\n",
        "        if output_attentions: # Manual attention computation\n",
        "            L, S = query_BLD.size(-2), key_BLD.size(-2)\n",
        "            scale = 1 / math.sqrt(query_BLD.size(-1))\n",
        "            attn_bias = torch.zeros(L, S, dtype=query_BLD.dtype, device=query_BLD.device)\n",
        "            if attention_mask is not None:\n",
        "                if attention_mask.dtype == torch.bool:\n",
        "                    attention_mask.masked_fill_(attention_mask.logical_not(), float('-inf'))\n",
        "                else:\n",
        "                    attn_bias += attention_mask\n",
        "\n",
        "            attn_weights = torch.matmul(query_BHLD, key_BHLD.transpose(-2, -1)) * scale\n",
        "            attn_weights += attn_bias\n",
        "            attn_weights = F.softmax(attn_weights, dim=-1)\n",
        "            context_BHLD = torch.matmul(attn_weights, value_BHLD)\n",
        "        else:\n",
        "            context_BHLD = F.scaled_dot_product_attention(\n",
        "                query_BHLD, key_BHLD, value_BHLD, attention_mask\n",
        "            )\n",
        "\n",
        "        context_BLD = rearrange(context_BHLD, \"b h s d -> b s (h d)\")\n",
        "        output = self.out_proj(context_BLD)\n",
        "        return output, attn_weights\n",
        "\n",
        "\n",
        "### Regression Head\n",
        "def RegressionHead(d_model: int, output_dim: int, hidden_dim: Optional[int] = None) -> nn.Module:\n",
        "    \"\"\"Create a regression head with optional hidden dimension.\n",
        "\n",
        "    Args:\n",
        "        d_model: Input dimension\n",
        "        output_dim: Output dimension\n",
        "        hidden_dim: Optional hidden dimension (defaults to d_model)\n",
        "    \"\"\"\n",
        "    hidden_dim = hidden_dim if hidden_dim is not None else d_model\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(d_model, hidden_dim),\n",
        "        nn.GELU(),\n",
        "        nn.LayerNorm(hidden_dim),\n",
        "        nn.Linear(hidden_dim, output_dim),\n",
        "    )\n",
        "\n",
        "\n",
        "### Model Outputs\n",
        "@dataclass\n",
        "class TransformerOutput(ModelOutput):\n",
        "    \"\"\"Output type for transformer encoder.\"\"\"\n",
        "    last_hidden_state: Optional[torch.Tensor] = None\n",
        "    hidden_states: Optional[Tuple[torch.Tensor]] = None\n",
        "    attentions: Optional[Tuple[torch.Tensor]] = None\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ESMplusplusOutput(ModelOutput):\n",
        "    \"\"\"Output type for ESM++ models.\"\"\"\n",
        "    loss: Optional[torch.Tensor] = None\n",
        "    logits: Optional[torch.Tensor] = None\n",
        "    last_hidden_state: Optional[torch.Tensor] = None\n",
        "    hidden_states: Optional[Tuple[torch.Tensor]] = None\n",
        "    attentions: Optional[Tuple[torch.Tensor]] = None\n",
        "\n",
        "\n",
        "### Transformer Stack\n",
        "class TransformerStack(nn.Module):\n",
        "    \"\"\"Stack of transformer blocks.\n",
        "\n",
        "    Args:\n",
        "        d_model: Model dimension\n",
        "        n_heads: Number of attention heads\n",
        "        n_layers: Number of transformer layers\n",
        "        dropout: Dropout rate\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        d_model: int,\n",
        "        n_heads: int,\n",
        "        n_layers: int,\n",
        "        dropout: float = 0.0,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.blocks = nn.ModuleList(\n",
        "            [\n",
        "                UnifiedTransformerBlock(\n",
        "                    d_model,\n",
        "                    n_heads,\n",
        "                    residue_scaling_factor=math.sqrt(n_layers / 36),\n",
        "                    dropout=dropout,\n",
        "                )\n",
        "                for i in range(n_layers)\n",
        "            ]\n",
        "        )\n",
        "        self.norm = nn.LayerNorm(d_model, bias=False)\n",
        "        self.gradient_checkpointing = False\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x: torch.Tensor,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        output_hidden_states: bool = False,\n",
        "        output_attentions: bool = False,\n",
        "    ) -> TransformerOutput:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor\n",
        "            attention_mask: Optional attention mask\n",
        "            output_hidden_states: Whether to return all hidden states\n",
        "            output_attentions: Whether to return attention weights\n",
        "\n",
        "        Returns:\n",
        "            TransformerOutput containing last hidden state and optionally all hidden states and attention weights\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, _ = x.shape\n",
        "        hidden_states = () if output_hidden_states else None\n",
        "        attentions = () if output_attentions else None\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attention_mask = attention_mask[:, None, None, :].expand(batch_size, 1, seq_len, seq_len).bool()\n",
        "\n",
        "        for block in self.blocks:\n",
        "            if self.gradient_checkpointing and self.training:\n",
        "                x, attn_weights = self._gradient_checkpointing_func(\n",
        "                    block.__call__,\n",
        "                    x,\n",
        "                    attention_mask,\n",
        "                    output_attentions,\n",
        "                )\n",
        "            else:\n",
        "                x, attn_weights = block(x, attention_mask, output_attentions)\n",
        "\n",
        "            if attentions is not None:\n",
        "                attentions += (attn_weights,)\n",
        "\n",
        "            if output_hidden_states:\n",
        "                assert hidden_states is not None\n",
        "                hidden_states += (x,)\n",
        "\n",
        "        return TransformerOutput(\n",
        "            last_hidden_state=self.norm(x),\n",
        "            hidden_states=hidden_states,\n",
        "            attentions=attentions\n",
        "        )\n",
        "\n"
      ],
      "metadata": {
        "id": "yHM9hTRaBkuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset for Protein Sequences Embedding"
      ],
      "metadata": {
        "id": "s3zb9BftFar7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Dataset for Embedding\n",
        "class ProteinDataset(Dataset):\n",
        "    \"\"\"Simple dataset for protein sequences.\"\"\"\n",
        "    def __init__(self, sequences: list[str]):\n",
        "        self.sequences = sequences\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> str:\n",
        "        return self.sequences[idx]\n",
        "\n",
        "\n",
        "class PreTrainedESMplusplusModel(PreTrainedModel):\n",
        "    \"\"\"\n",
        "    init weights for ESM++ models\n",
        "    \"\"\"\n",
        "    config_class = ESMplusplusConfig\n",
        "    base_model_prefix = \"esm++\"\n",
        "    supports_gradient_checkpointing = True\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        \"\"\"Initialize the weights\"\"\"\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if module.padding_idx is not None:\n",
        "                module.weight.data[module.padding_idx].zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained_esm(cls, model_name: str):\n",
        "        \"\"\"Load a pretrained ESM++ model.\"\"\"\n",
        "        if '300' in model_name:\n",
        "            return ESMplusplus_300M()\n",
        "        elif '600' in model_name:\n",
        "            return ESMplusplus_600M()\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid model name: {model_name}\")\n",
        "\n",
        "    @property\n",
        "    def device(self) -> torch.device:\n",
        "        \"\"\"Get the device of the model.\"\"\"\n",
        "        return next(self.parameters()).device\n",
        "\n",
        "    def mean_pooling(self, x: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        \"\"\"Apply mean pooling to sequence outputs.\"\"\"\n",
        "        if attention_mask is None:\n",
        "            return x.mean(dim=1)\n",
        "        else:\n",
        "            attention_mask = attention_mask.unsqueeze(-1)\n",
        "            return (x * attention_mask).sum(dim=1) / attention_mask.sum(dim=1)\n",
        "\n",
        "    def max_pooling(self, x: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        \"\"\"Apply max pooling to sequence outputs.\"\"\"\n",
        "        if attention_mask is None:\n",
        "            return x.max(dim=1).values\n",
        "        else:\n",
        "            attention_mask = attention_mask.unsqueeze(-1)\n",
        "            return (x * attention_mask).max(dim=1).values\n",
        "\n",
        "    def cls_pooling(self, x: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        \"\"\"Apply cls pooling to sequence outputs.\"\"\"\n",
        "        return x[:, 0, :]\n",
        "\n",
        "    def _collate_fn(self, sequences: list[str]) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"Collate function for batching sequences.\"\"\"\n",
        "        return self.tokenizer(sequences, return_tensors=\"pt\", padding='longest', pad_to_multiple_of=8)\n",
        "\n",
        "    def _read_sequences_from_db(self, db_path: str) -> set[str]:\n",
        "        \"\"\"Read sequences from SQLite database.\"\"\"\n",
        "        import sqlite3\n",
        "        sequences = []\n",
        "        with sqlite3.connect(db_path) as conn:\n",
        "            c = conn.cursor()\n",
        "            c.execute(\"SELECT sequence FROM embeddings\")\n",
        "            while True:\n",
        "                row = c.fetchone()\n",
        "                if row is None:\n",
        "                    break\n",
        "                sequences.append(row[0])\n",
        "        return set(sequences)\n",
        "\n",
        "    def embed_dataset(\n",
        "        self,\n",
        "        sequences: list[str],\n",
        "        batch_size: int = 2,\n",
        "        max_len: int = 512,\n",
        "        full_embeddings: bool = False,\n",
        "        full_precision: bool = False,\n",
        "        pooling_type: str = 'mean',\n",
        "        num_workers: int = 0,\n",
        "        sql: bool = False,\n",
        "        sql_db_path: str = 'embeddings.db',\n",
        "    ) -> Optional[dict[str, torch.Tensor]]:\n",
        "        \"\"\"Embed a dataset of protein sequences.\n",
        "\n",
        "        Args:\n",
        "            sequences: List of protein sequences\n",
        "            batch_size: Batch size for processing\n",
        "            max_len: Maximum sequence length\n",
        "            full_embeddings: Whether to return full residue-wise (True) embeddings or pooled (False)\n",
        "            full_precision: Whether to cast to full precision (float32) before storage - relevant for dict storage\n",
        "            pooling_type: Type of pooling ('mean' or 'cls')\n",
        "            num_workers: Number of workers for data loading, 0 for the main process\n",
        "            sql: Whether to store embeddings in SQLite database - will be stored in float32\n",
        "            sql_db_path: Path to SQLite database\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping sequences to embeddings, or None if sql=True\n",
        "        \"\"\"\n",
        "        sequences = list(set([seq[:max_len] for seq in sequences]))\n",
        "        device = self.device\n",
        "\n",
        "        def get_embeddings(residue_embeddings: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "            if full_embeddings:\n",
        "                return residue_embeddings\n",
        "            elif pooling_type == 'mean':\n",
        "                return self.mean_pooling(residue_embeddings, attention_mask)\n",
        "            elif pooling_type == 'max':\n",
        "                return self.max_pooling(residue_embeddings, attention_mask)\n",
        "            elif pooling_type == 'cls':\n",
        "                return self.cls_pooling(residue_embeddings, attention_mask)\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid pooling type: {pooling_type}\")\n",
        "\n",
        "        sequences = list(set([seq[:max_len] for seq in sequences]))\n",
        "        if sql:\n",
        "            import sqlite3\n",
        "            conn = sqlite3.connect(sql_db_path)\n",
        "            c = conn.cursor()\n",
        "            c.execute('CREATE TABLE IF NOT EXISTS embeddings (sequence text PRIMARY KEY, embedding blob)')\n",
        "            already_embedded = self._read_sequences_from_db(sql_db_path)\n",
        "            to_embed = [seq for seq in sequences if seq not in already_embedded]\n",
        "            print(f\"Found {len(already_embedded)} already embedded sequences in {sql_db_path}\")\n",
        "            print(f\"Embedding {len(to_embed)} new sequences\")\n",
        "            if len(to_embed) > 0:\n",
        "                to_embed = sorted(to_embed, key=len, reverse=True)\n",
        "                dataset = ProteinDataset(to_embed)\n",
        "                dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, collate_fn=self._collate_fn, shuffle=False)\n",
        "                with torch.no_grad():\n",
        "                    for i, batch in tqdm(enumerate(dataloader), total=len(dataloader), desc='Embedding batches'):\n",
        "                        seqs = to_embed[i * batch_size:(i + 1) * batch_size]\n",
        "                        input_ids, attention_mask = batch['input_ids'].to(device), batch['attention_mask'].to(device)\n",
        "                        x = self.embed(input_ids)\n",
        "                        residue_embeddings = self.transformer(x, attention_mask).last_hidden_state.detach().float() # required for sql\n",
        "                        embeddings = get_embeddings(residue_embeddings, attention_mask)\n",
        "\n",
        "                        for seq, emb, mask in zip(seqs, embeddings, attention_mask):\n",
        "                            if full_embeddings:\n",
        "                                emb = emb[mask.bool()]\n",
        "                            c.execute(\"INSERT OR REPLACE INTO embeddings VALUES (?, ?)\",\n",
        "                                    (seq, emb.cpu().numpy().tobytes()))\n",
        "\n",
        "                        if (i + 1) % 100 == 0:\n",
        "                            conn.commit()\n",
        "\n",
        "                conn.commit()\n",
        "            conn.close()\n",
        "            return None\n",
        "\n",
        "        embeddings_dict = {}\n",
        "        sequences = sorted(sequences, key=len, reverse=True)\n",
        "        dataset = ProteinDataset(sequences)\n",
        "        dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, collate_fn=self._collate_fn, shuffle=False)\n",
        "        with torch.no_grad():\n",
        "            for i, batch in tqdm(enumerate(dataloader), total=len(dataloader), desc='Embedding batches'):\n",
        "                seqs = sequences[i * batch_size:(i + 1) * batch_size]\n",
        "                input_ids, attention_mask = batch['input_ids'].to(device), batch['attention_mask'].to(device)\n",
        "                x = self.embed(input_ids)\n",
        "                residue_embeddings = self.transformer(x, attention_mask).last_hidden_state.detach()\n",
        "                if full_precision:\n",
        "                    residue_embeddings = residue_embeddings.float()\n",
        "                embeddings = get_embeddings(residue_embeddings, attention_mask).cpu()\n",
        "                for seq, emb in zip(seqs, embeddings):\n",
        "                    embeddings_dict[seq] = emb\n",
        "\n",
        "        return embeddings_dict\n"
      ],
      "metadata": {
        "id": "cMMexauFFcQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ESM++ Models with masked language modeling head"
      ],
      "metadata": {
        "id": "mUtnu9OOGLTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ESM++ Models\n",
        "class ESMplusplusModel(PreTrainedESMplusplusModel):\n",
        "    \"\"\"\n",
        "    ESM++ model. transformer model with no heads\n",
        "    \"\"\"\n",
        "    config_class = ESMplusplusConfig\n",
        "    def __init__(self, config: ESMplusplusConfig, **kwargs):\n",
        "        super().__init__(config, **kwargs)\n",
        "        self.config = config\n",
        "        self.vocab_size = config.vocab_size\n",
        "        self.embed = nn.Embedding(self.vocab_size, config.hidden_size)\n",
        "        self.transformer = TransformerStack(config.hidden_size, config.num_attention_heads, config.num_hidden_layers, config.dropout)\n",
        "        self.tokenizer = EsmSequenceTokenizer()\n",
        "        self.init_weights()\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        return self.embed\n",
        "\n",
        "    def set_input_embeddings(self, value):\n",
        "        self.embed = value\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None, # to play nice with HF adjacent packages\n",
        "    ) -> TransformerOutput:\n",
        "        \"\"\"Forward pass for masked language modeling.\n",
        "\n",
        "        Args:\n",
        "            input_ids: Input token IDs\n",
        "            attention_mask: Attention mask\n",
        "            inputs_embeds: Optional precomputed embeddings\n",
        "            output_hidden_states: Whether to return all hidden states\n",
        "            output_attentions: Whether to return attention weights\n",
        "\n",
        "        Returns:\n",
        "            TransformerOutput containing last hidden state and optionally all hidden states and attention weights\n",
        "        \"\"\"\n",
        "        if inputs_embeds is None:\n",
        "            x = self.embed(input_ids)\n",
        "        else:\n",
        "            x = inputs_embeds\n",
        "        return self.transformer(x, attention_mask, output_hidden_states, output_attentions)\n",
        "\n",
        "\n",
        "class ESMplusplusForMaskedLM(PreTrainedESMplusplusModel):\n",
        "    \"\"\"\n",
        "    ESM++ model for masked language modeling.\n",
        "    Implements the base ESM++ architecture with a masked language modeling head.\n",
        "    \"\"\"\n",
        "    config_class = ESMplusplusConfig\n",
        "    def __init__(self, config: ESMplusplusConfig, **kwargs):\n",
        "        super().__init__(config, **kwargs)\n",
        "        self.config = config\n",
        "        self.vocab_size = config.vocab_size\n",
        "        self.embed = nn.Embedding(self.vocab_size, config.hidden_size)\n",
        "        self.transformer = TransformerStack(config.hidden_size, config.num_attention_heads, config.num_hidden_layers, config.dropout)\n",
        "        self.sequence_head = RegressionHead(config.hidden_size, self.vocab_size)\n",
        "        self.ce_loss = nn.CrossEntropyLoss()\n",
        "        self.tokenizer = EsmSequenceTokenizer()\n",
        "        self.init_weights()\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        return self.embed\n",
        "\n",
        "    def set_input_embeddings(self, value):\n",
        "        self.embed = value\n",
        "\n",
        "    def get_output_embeddings(self):\n",
        "        return self.sequence_head[-1]\n",
        "\n",
        "    def set_output_embeddings(self, new_embeddings):\n",
        "        self.sequence_head[-1] = new_embeddings\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        labels: Optional[torch.Tensor] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None, # to play nice with HF adjacent packages\n",
        "    ) -> ESMplusplusOutput:\n",
        "        \"\"\"Forward pass for masked language modeling.\n",
        "\n",
        "        Args:\n",
        "            input_ids: Input token IDs\n",
        "            attention_mask: Attention mask\n",
        "            inputs_embeds: Optional precomputed embeddings\n",
        "            labels: Optional labels for masked tokens\n",
        "            output_hidden_states: Whether to return all hidden states\n",
        "            output_attentions: Whether to return attention weights\n",
        "\n",
        "        Returns:\n",
        "            ESMplusplusOutput containing loss, logits, hidden states and attention weights\n",
        "        \"\"\"\n",
        "        if inputs_embeds is None:\n",
        "            x = self.embed(input_ids)\n",
        "        else:\n",
        "            x = inputs_embeds\n",
        "        output = self.transformer(x, attention_mask, output_hidden_states, output_attentions)\n",
        "        x = output.last_hidden_state\n",
        "        logits = self.sequence_head(x)\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = self.ce_loss(logits.view(-1, self.vocab_size), labels.view(-1))\n",
        "        return ESMplusplusOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            last_hidden_state=x,\n",
        "            hidden_states=output.hidden_states,\n",
        "            attentions=output.attentions,\n",
        "        )\n"
      ],
      "metadata": {
        "id": "G7lYIkzAGLfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ESM++ model for sequence and token classification\n",
        "Extends the base ESM++ model with a classification head for either sequence or token classification tasks."
      ],
      "metadata": {
        "id": "vqrL7mPCGdGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ESMplusplusForSequenceClassification(ESMplusplusForMaskedLM):\n",
        "    \"\"\"\n",
        "    ESM++ model for sequence classification.\n",
        "    Extends the base ESM++ model with a classification head.\n",
        "    \"\"\"\n",
        "    def __init__(self, config: ESMplusplusConfig, **kwargs):\n",
        "        super().__init__(config, **kwargs)\n",
        "        self.config = config\n",
        "        self.num_labels = config.num_labels\n",
        "        self.classifier = RegressionHead(config.hidden_size * 2, config.num_labels, config.hidden_size * 4)\n",
        "        # Large intermediate projections help with sequence classification tasks (*4)\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.ce = nn.CrossEntropyLoss()\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        labels: Optional[torch.Tensor] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None, # to play nice with HF adjacent packages\n",
        "    ) -> ESMplusplusOutput:\n",
        "        \"\"\"Forward pass for sequence classification.\n",
        "\n",
        "        Args:\n",
        "            input_ids: Input token IDs\n",
        "            attention_mask: Attention mask\n",
        "            inputs_embeds: Optional precomputed embeddings\n",
        "            labels: Optional labels for classification\n",
        "            output_hidden_states: Whether to return all hidden states\n",
        "            output_attentions: Whether to return attention weights\n",
        "\n",
        "        Returns:\n",
        "            ESMplusplusOutput containing loss, logits, and hidden states\n",
        "        \"\"\"\n",
        "        output = super().forward(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            labels=None,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states\n",
        "        )\n",
        "        x = output.last_hidden_state\n",
        "        cls_features = x[:, 0, :]\n",
        "        mean_features = self.mean_pooling(x, attention_mask)\n",
        "        # we include mean pooling features to help with early convergence, the cost of this is basically zero\n",
        "        features = torch.cat([cls_features, mean_features], dim=-1)\n",
        "        logits = self.classifier(features)\n",
        "\n",
        "        # # Use this:\n",
        "        # pooled_embedding = self.mean_pooling(x, attention_mask)  # Calculate pooled embedding\n",
        "        # logits = self.classifier(pooled_embedding)  # Pass pooled embedding to classifier\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            labels = labels.to(logits.device)\n",
        "            if self.config.problem_type is None:\n",
        "                if self.num_labels == 1:\n",
        "                    self.config.problem_type = \"regression\"\n",
        "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
        "                    self.config.problem_type = \"single_label_classification\"\n",
        "                else:\n",
        "                    self.config.problem_type = \"multi_label_classification\"\n",
        "\n",
        "            if self.config.problem_type == \"regression\":\n",
        "                if self.num_labels == 1:\n",
        "                    loss = self.mse(logits.flatten(), labels.flatten())\n",
        "                else:\n",
        "                    loss = self.mse(logits, labels)\n",
        "            elif self.config.problem_type == \"single_label_classification\":\n",
        "                loss = self.ce(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            elif self.config.problem_type == \"multi_label_classification\":\n",
        "                loss = self.bce(logits, labels)\n",
        "\n",
        "        return ESMplusplusOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            last_hidden_state=x,\n",
        "            hidden_states=output.hidden_states,\n",
        "        )\n",
        "\n",
        "\n",
        "class ESMplusplusForTokenClassification(ESMplusplusForMaskedLM):\n",
        "    \"\"\"\n",
        "    ESM++ model for token classification.\n",
        "    Extends the base ESM++ model with a token classification head.\n",
        "    \"\"\"\n",
        "    def __init__(self, config: ESMplusplusConfig):\n",
        "        super().__init__(config)\n",
        "        self.config = config\n",
        "        self.num_labels = config.num_labels\n",
        "        self.classifier = RegressionHead(config.hidden_size, config.num_labels, config.hidden_size * 4)\n",
        "        # Large intermediate projections help with sequence classification tasks (*4)\n",
        "        self.loss_fct = nn.CrossEntropyLoss()\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        labels: Optional[torch.Tensor] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None, # to play nice with HF adjacent packages\n",
        "    ) -> ESMplusplusOutput:\n",
        "        \"\"\"Forward pass for token classification.\n",
        "\n",
        "        Args:\n",
        "            input_ids: Input token IDs\n",
        "            attention_mask: Attention mask\n",
        "            inputs_embeds: Optional precomputed embeddings\n",
        "            labels: Optional labels for token classification\n",
        "            output_hidden_states: Whether to return all hidden states\n",
        "            output_attentions: Whether to return attention weights\n",
        "\n",
        "        Returns:\n",
        "            ESMplusplusOutput containing loss, logits, and hidden states\n",
        "        \"\"\"\n",
        "        output = super().forward(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            labels=None,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states\n",
        "        )\n",
        "        x = output.last_hidden_state\n",
        "        logits = self.classifier(x)\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = self.loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "        return ESMplusplusOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            last_hidden_state=x,\n",
        "            hidden_states=output.hidden_states,\n",
        "        )\n"
      ],
      "metadata": {
        "id": "lMX9_L-aGdPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading from EvolutionaryScale ESMplusplus models and sequence tokenizer"
      ],
      "metadata": {
        "id": "vIx6IE5NGqk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Loading from EvolutionaryScale\n",
        "@staticmethod\n",
        "@cache\n",
        "def data_root(model: str):\n",
        "    if \"INFRA_PROVIDER\" in os.environ:\n",
        "        return Path(\"\")\n",
        "    # Try to download from hugginface if it doesn't exist\n",
        "    if model.startswith(\"esmc-300\"):\n",
        "        path = Path(snapshot_download(repo_id=\"EvolutionaryScale/esmc-300m-2024-12\"))\n",
        "    elif model.startswith(\"esmc-600\"):\n",
        "        path = Path(snapshot_download(repo_id=\"EvolutionaryScale/esmc-600m-2024-12\"))\n",
        "    else:\n",
        "        raise ValueError(f\"{model=} is an invalid model name.\")\n",
        "    return path\n",
        "\n",
        "\n",
        "def ESMplusplus_300M(device: torch.device | str = \"cpu\", num_labels: int = 3):\n",
        "    with torch.device(device):\n",
        "        config = ESMplusplusConfig(\n",
        "            hidden_size=960,\n",
        "            num_attention_heads=15,\n",
        "            num_hidden_layers=30,\n",
        "            num_labels=num_labels,\n",
        "        )\n",
        "        model = ESMplusplusForMaskedLM(config)\n",
        "    state_dict = torch.load(\n",
        "        data_root(\"esmc-300\") / \"data/weights/esmc_300m_2024_12_v0.pth\",\n",
        "        map_location=device,\n",
        "    )\n",
        "    model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def ESMplusplus_600M(device: torch.device | str = \"cpu\", num_labels: int = 3):\n",
        "    with torch.device(device):\n",
        "        config = ESMplusplusConfig(\n",
        "            hidden_size=1152,\n",
        "            num_attention_heads=18,\n",
        "            num_hidden_layers=36,\n",
        "            num_labels=num_labels,\n",
        "        )\n",
        "        model = ESMplusplusForMaskedLM(config)\n",
        "        # # Use ESMplusplusForSequenceClassification to create the model with classification head\n",
        "        # model = ESMplusplusForSequenceClassification(config)\n",
        "    state_dict = torch.load(\n",
        "        data_root(\"esmc-600\") / \"data/weights/esmc_600m_2024_12_v0.pth\",\n",
        "        map_location=device,\n",
        "    )\n",
        "    model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "### Tokenization\n",
        "SEQUENCE_VOCAB = [\n",
        "    \"<cls>\", \"<pad>\", \"<eos>\", \"<unk>\",\n",
        "    \"L\", \"A\", \"G\", \"V\", \"S\", \"E\", \"R\", \"T\", \"I\", \"D\", \"P\", \"K\",\n",
        "    \"Q\", \"N\", \"F\", \"Y\", \"M\", \"H\", \"W\", \"C\", \"X\", \"B\", \"U\", \"Z\",\n",
        "    \"O\", \".\", \"-\", \"|\",\n",
        "    \"<mask>\",\n",
        "]\n",
        "\n",
        "class EsmSequenceTokenizer(PreTrainedTokenizerFast):\n",
        "    model_input_names = [\"input_ids\", \"attention_mask\"]\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        unk_token=\"<unk>\",\n",
        "        cls_token=\"<cls>\",\n",
        "        pad_token=\"<pad>\",\n",
        "        mask_token=\"<mask>\",\n",
        "        eos_token=\"<eos>\",\n",
        "        chain_break_token=\"|\",\n",
        "        **kwargs,\n",
        "    ):\n",
        "        all_tokens = SEQUENCE_VOCAB\n",
        "        token_to_id = {tok: ind for ind, tok in enumerate(all_tokens)}\n",
        "\n",
        "        # a character-level tokenizer is the same as BPE with no token merges\n",
        "        bpe = BPE(token_to_id, merges=[], unk_token=unk_token)\n",
        "        tokenizer = Tokenizer(bpe)\n",
        "        special_tokens = [\n",
        "            cls_token,\n",
        "            pad_token,\n",
        "            mask_token,\n",
        "            eos_token,\n",
        "            chain_break_token,\n",
        "        ]\n",
        "        self.cb_token = chain_break_token\n",
        "        additional_special_tokens = [chain_break_token]\n",
        "\n",
        "        tokenizer.add_special_tokens(special_tokens)\n",
        "\n",
        "        # This is where we configure the automatic addition of special tokens when we call\n",
        "        # tokenizer(text, add_special_tokens=True). Note that you can also configure how two\n",
        "        # sequences are merged if you want.\n",
        "        tokenizer.post_processor = TemplateProcessing(  # type: ignore\n",
        "            single=\"<cls> $A <eos>\",\n",
        "            special_tokens=[\n",
        "                (\"<cls>\", tokenizer.token_to_id(\"<cls>\")),\n",
        "                (\"<eos>\", tokenizer.token_to_id(\"<eos>\")),\n",
        "            ],\n",
        "        )\n",
        "        super().__init__(\n",
        "            tokenizer_object=tokenizer,\n",
        "            unk_token=unk_token,\n",
        "            cls_token=cls_token,\n",
        "            pad_token=pad_token,\n",
        "            mask_token=mask_token,\n",
        "            eos_token=eos_token,\n",
        "            additional_special_tokens=additional_special_tokens,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "    # These are a footgun, we never use the `bos` token anywhere so we're just overriding it here.\n",
        "    @property\n",
        "    def bos_token(self):\n",
        "        return self.cls_token\n",
        "\n",
        "    @property\n",
        "    def bos_token_id(self):\n",
        "        return self.cls_token_id\n",
        "\n",
        "    @property\n",
        "    def chain_break_token(self):\n",
        "        return self.cb_token\n",
        "\n",
        "    @property\n",
        "    def chain_break_token_id(self):\n",
        "        return self.convert_tokens_to_ids(self.chain_break_token)\n",
        "\n",
        "    @property\n",
        "    def all_token_ids(self):\n",
        "        return list(range(self.vocab_size))\n",
        "\n",
        "    @property\n",
        "    def special_token_ids(self):\n",
        "        return self.all_special_ids\n"
      ],
      "metadata": {
        "id": "gLpKZEQRGqvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My protein input data\n",
        "Formatted as required in the notebook `clean_myprot_PT5_LoRA_Finetuning_per_prot.ipynb`, I will modify it accordingly here."
      ],
      "metadata": {
        "id": "9rHgKC2d_JCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Bio"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FomD5CSp-wdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import SeqIO\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "input_seqs_path = \"/content/drive/My Drive/LLMs_data/input_seq/extracted_polymer_deg_proteins_1241_metagenomes_pident50_len550_final_format.tsv\"\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device: {}\".format(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVNgTvC3-waE",
        "outputId": "6af12fd7-7821-47d6-abf6-ee10007dc8be"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Using device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3-ways split into train, test, val sets with each class distribution\n",
        "\n",
        "def stratified_3_split(df, target_col=\"target\", train_size=0.7, val_size=0.15, test_size=0.15, random_state=42):\n",
        "    \"\"\"\n",
        "    Splits a DataFrame into train, validation, and test sets while preserving class distribution.\n",
        "\n",
        "    Args:\n",
        "    - df (pd.DataFrame): The input DataFrame containing features and target labels.\n",
        "    - target_col (str): The column name containing the class labels.\n",
        "    - train_size (float): Proportion of data to allocate for training.\n",
        "    - val_size (float): Proportion of data to allocate for validation.\n",
        "    - test_size (float): Proportion of data to allocate for testing.\n",
        "    - random_state (int): Random seed for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "    - train_df (pd.DataFrame): Training dataset.\n",
        "    - val_df (pd.DataFrame): Validation dataset.\n",
        "    - test_df (pd.DataFrame): Test dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure proportions sum to 1\n",
        "    assert train_size + val_size + test_size == 1, \"Train, val, and test sizes must sum to 1.\"\n",
        "\n",
        "    # Extract features and labels\n",
        "    X = df.drop(columns=[target_col])\n",
        "    y = df[target_col]\n",
        "\n",
        "    # First, split into train (train_size) and temp (val_size + test_size)\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "        X, y, test_size=(val_size + test_size), stratify=y, random_state=random_state\n",
        "    )\n",
        "\n",
        "    # Then, split temp into validation and test sets\n",
        "    X_val, X_test, y_val, y_test = train_test_split(\n",
        "        X_temp, y_temp, test_size=(test_size / (val_size + test_size)), stratify=y_temp, random_state=random_state\n",
        "    )\n",
        "\n",
        "    # Reassemble into DataFrames\n",
        "    train_df = X_train.copy()\n",
        "    train_df[target_col] = y_train\n",
        "    val_df = X_val.copy()\n",
        "    val_df[target_col] = y_val\n",
        "    test_df = X_test.copy()\n",
        "    test_df[target_col] = y_test\n",
        "\n",
        "    return train_df, val_df, test_df"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NZHk6-zqAQ5I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_for_llm = pd.read_csv(input_seqs_path, sep=\"\\t\")\n",
        "print(data_for_llm.shape)\n",
        "data_for_llm.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "m67LYoE6AYWk",
        "outputId": "be65040d-4ed1-46d7-c11d-ff771ff72e07"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4367, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 query                                           sequence  \\\n",
              "0  JACDJC010024513.1_3  MFRFHIVSALLTLFIAVPSQAHDVGQREIKISGAEPGRNLEVSVWY...   \n",
              "1  JAHZTL010540190.1_2  MRAWWLSGALALMFWAQGAVAGTLLVVGDSISAAFGLDSRQGWVAL...   \n",
              "2  JAHZTT010011795.1_8  MRAWWLSGALALMFWAQGAVAGTLLVVGDSISAAFGLDSRQGWVAL...   \n",
              "3  JANPXX010012215.1_8  MRAWWLSGALALMFWAQGAVAGTLLVVGDSISAAFGLDSRQGWVAL...   \n",
              "4   LAZR01000025.1_143  MQFLLGLIGLLLLIVTSLRRWLLRRESPQKQAVDFHGELYQVGSAV...   \n",
              "\n",
              "   label  \n",
              "0      2  \n",
              "1      0  \n",
              "2      0  \n",
              "3      0  \n",
              "4      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-537d7ee6-94bb-4f3e-ac75-04befe96de55\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>sequence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>JACDJC010024513.1_3</td>\n",
              "      <td>MFRFHIVSALLTLFIAVPSQAHDVGQREIKISGAEPGRNLEVSVWY...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>JAHZTL010540190.1_2</td>\n",
              "      <td>MRAWWLSGALALMFWAQGAVAGTLLVVGDSISAAFGLDSRQGWVAL...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>JAHZTT010011795.1_8</td>\n",
              "      <td>MRAWWLSGALALMFWAQGAVAGTLLVVGDSISAAFGLDSRQGWVAL...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>JANPXX010012215.1_8</td>\n",
              "      <td>MRAWWLSGALALMFWAQGAVAGTLLVVGDSISAAFGLDSRQGWVAL...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LAZR01000025.1_143</td>\n",
              "      <td>MQFLLGLIGLLLLIVTSLRRWLLRRESPQKQAVDFHGELYQVGSAV...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-537d7ee6-94bb-4f3e-ac75-04befe96de55')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-537d7ee6-94bb-4f3e-ac75-04befe96de55 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-537d7ee6-94bb-4f3e-ac75-04befe96de55');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-02ed9011-5c78-4f49-830f-2c550208978d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-02ed9011-5c78-4f49-830f-2c550208978d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-02ed9011-5c78-4f49-830f-2c550208978d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_for_llm",
              "summary": "{\n  \"name\": \"data_for_llm\",\n  \"rows\": 4367,\n  \"fields\": [\n    {\n      \"column\": \"query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4367,\n        \"samples\": [\n          \"JAWMQX010851707.1_1\",\n          \"JAWMQY011396312.1_2\",\n          \"JAUJDY010000031.1_21\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3340,\n        \"samples\": [\n          \"MSEPLILQPTLAADSCVIWLHGLGADRYDFMPVAEALQQRLHSTRFVLPQAPTQAVTINGGYAMPSWYDILAMSPARAINRDQLEASAQQVIALIEAQRDSGIDPARIVLAGFSQGGAVVLHTAFLRWQFALGGVMALSTYAPTFSDENTLADTKKQLPVLCLHGTFDDIVLPAMGRAAHDYLEASGVSVQWRDYPMGHEVVNEEIRDIADWLELRFNS*\",\n          \"MKKINHLFFLLACICSLNTTYAQQNIIEVEGGKISGVMNNYKTVESFKGIPFAAPPVGDLRWRAPQPVQPWNGVLACTKFSASPMQAKPVPFSMWSEEFLIPAEPISEDCLYLNVWTANKNKKNKQPVLVWIYGGGFGSGGTACPIYDGEALAKKGIVVVSINYRVGVFGFFAHPDLNEQSGNFGMLDQIAALKWVKKNIAAFGGDPDQVTISGQSAGSMSVNTLVASPLAAGLFNKAIAQSGGNFSRGNSSKSNAEAEGLKYAALFSAKTVAELKKVDAELLMKKFIGIRGPYIDGHVLPEHILDIFQKGNQNKVALLVGWNQDEGLMMSPAKSAENLRKDFQQQYGSNADAFLKFYPSSNDEEAKQTQLDLSRDQIFGMPGLIWANFQEAQSLPVYVYRFTRIVPAEGQYKQYKAFHTGEVPYMFDNLRFVRRPWEPADHELAKSMSDYWVSFVKTGNPNHSKALNWPLFNSKEKPTLYFDSKNKVAPMEDAERLNYLFSSMTANK*\",\n          \"MNTLSWIRSVNGTLGHLAPEHVARKMRRAFMTPRNRPPRDWELPLLARAERITLRFGLSALRWGQGPTVLLMHGWEGRPTQFAHLIDSLVDAGYTAVALEGPAHGHSPGNEANVVLFARALLEAAAELPPLKAVVGHSMGGASMLLALQWGLRAEVAVSIAAPAQLLGVIRGFARHLGMPARARAAFIRQIERDVGVQISRLDVSGYQLELPGLIVHAEDDQLVPVDESDAIHRAWFDSRLLRLPDGGHLRVLADPQLREGVLALLQRSSSPARQSA*\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Need to remove duplicate sequences first in order to proceed with modeling**"
      ],
      "metadata": {
        "id": "xNgiR4SR1oCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_for_llm = data_for_llm.drop_duplicates(subset=['sequence'], keep='first')\n",
        "print(data_for_llm.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMKZ1z8N1oPl",
        "outputId": "86bcc948-84d5-4b2e-c1a7-325f592e7c1c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3340, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the length of each sequence and MAX:\n",
        "np.max(data_for_llm['sequence'].apply(len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3UDbJejDce7",
        "outputId": "aeb054a1-9a38-43d4-b7fc-08b7a5df926b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "550"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_train, my_valid, my_test = stratified_3_split(data_for_llm, target_col=\"label\")\n",
        "my_train = my_train[['sequence', 'label']]\n",
        "my_valid = my_valid[['sequence', 'label']]\n",
        "my_test = my_test[['sequence', 'label']]\n",
        "print(f'The size of each split: train_df={my_train.shape[0]}, val_df={my_valid.shape[0]}, test_df={my_test.shape[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnQG7X5IAYZ2",
        "outputId": "05fbddf5-f33c-4e9d-94f0-91c6817d1bbb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of each split: train_df=2338, val_df=501, test_df=501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Base code for fine-tuning ESM++ with LORA for specific classification task"
      ],
      "metadata": {
        "id": "_IRCRaWZKeb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets evaluate deepspeed"
      ],
      "metadata": {
        "collapsed": true,
        "id": "iYPhay7bBVo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset # TensorDataset is a PyTorch class that creates a dataset from tensors (embeddings + labels). It provides a way to access your data in pairs of (embedding, label) for training or evaluation.\n",
        "from transformers import TrainingArguments, Trainer, AutoModelForMaskedLM\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "# from datasets import Dataset # load_dataset\n",
        "from evaluate import load\n",
        "from transformers import EvalPrediction\n",
        "from sklearn.metrics import accuracy_score\n",
        "import deepspeed"
      ],
      "metadata": {
        "id": "V2yHs2HqGfuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(transformers.__version__)\n",
        "import peft\n",
        "print(peft.__version__)\n",
        "import evaluate\n",
        "print(evaluate.__version__)\n",
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tvqxz1Z_KqIV",
        "outputId": "5d425629-22f3-4791-a915-e010892e77dd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.48.3\n",
            "0.14.0\n",
            "0.4.3\n",
            "2.5.1+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the WANDB_API_KEY environment variable (this token is linked to my GitHub/WandB account)\n",
        "os.environ[\"WANDB_API_KEY\"] = \"81e81dc90b475f0264ec82b2f6376ca70bdd7c46\""
      ],
      "metadata": {
        "id": "Fdagl8sEX214"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set environment variables to run Deepspeed from a notebook\n",
        "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
        "os.environ[\"MASTER_PORT\"] = \"9994\"  # modify if RuntimeError: Address already in use\n",
        "os.environ[\"RANK\"] = \"0\"\n",
        "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
        "os.environ[\"WORLD_SIZE\"] = \"1\""
      ],
      "metadata": {
        "id": "X9RneQk3fbRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ESM++ models from EvolutionaryScale are not directly hosted on the Hugging Face Model Hub in the standard format expected by from_pretrained. They are provided in a different format within their own repository. Use the custom loading mechanism defined in the notebook itself.\n",
        "\n",
        "__Warning note: the pretrained model does not contain weights for the classification head.__\n",
        "\n",
        "_The original warning message:\n",
        "Some weights of ESMplusplusForSequenceClassification were not initialized from the model checkpoint at Synthyra/ESMplusplus_large and are newly initialized: ['classifier.0.bias', 'classifier.0.weight', 'classifier.2.bias', 'classifier.2.weight', 'classifier.3.bias', 'classifier.3.weight']\n",
        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference._\n",
        "\n",
        "__Note:\n",
        "strict=False:__ This is a crucial argument. It tells load_state_dict() to ignore any keys (parameters) in the state dictionary that are not found in the model_classification. Why is this important for your code? The model_embedding (ESM++ for MLM) has parameters for its backbone (embedding and transformer layers). The model_classification (ESM++ for sequence classification) has those same backbone parameters plus additional parameters for its classification head. By using strict=False, you can copy the shared backbone parameters from the pretrained model_embedding into the model_classification, while leaving the classification head's parameters untouched (they'll be initialized randomly or with some default). This enables transfer learning. You're taking the knowledge learned by the embedding model (about protein representations) and using it to initialize the backbone of the classification model."
      ],
      "metadata": {
        "id": "jm2lBb9VPLPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ESM++ for protein embeddings using a pre-trained model from Synthyra\n",
        "\n",
        "# model = AutoModelForMaskedLM.from_pretrained('Synthyra/ESMplusplus_large', trust_remote_code=True)\n",
        "# tokenizer = model.tokenizer\n",
        "\n",
        "# # Move model to GPU and keep them in float32\n",
        "# model = model.to(device)\n",
        "\n",
        "# embeddings = model.embed_dataset(\n",
        "#     sequences=list(my_valid['sequence']), # list of protein strings\n",
        "#     batch_size=16, # embedding batch size\n",
        "#     max_len=550, # truncate to max_len\n",
        "#     full_embeddings=False, # return full residue-wise (True) embeddings or pooled (False)\n",
        "#     full_precision=True, # store as float32\n",
        "#     pooling_type='mean', # use mean pooling if protein-wise embeddings\n",
        "#     num_workers=0, # data loading num workers\n",
        "#     sql=False, # return dictionary of sequences and embeddings\n",
        "# )\n",
        "\n",
        "\n",
        "# Dataset creation\n",
        "# def create_dataset(tokenizer, seqs, labels, padding=\"longest\", truncation=True, max_length=550):\n",
        "#     tokenized = tokenizer(seqs, max_length=max_length, padding=padding, truncation=truncation)\n",
        "#     dataset = Dataset.from_dict(tokenized)\n",
        "#     dataset = dataset.add_column(\"labels\", labels)\n",
        "\n",
        "#     return dataset\n",
        "\n",
        "# # Create Datasets\n",
        "# train_set=create_dataset(tokenizer,list(my_train['sequence'][0:20]),list(my_train['label'][0:20]))\n",
        "# valid_set=create_dataset(tokenizer,list(my_valid['sequence'][0:10]),list(my_valid['label'][0:10]))\n",
        "# test_set=create_dataset(tokenizer,list(my_test['sequence'][0:10]),list(my_test['label'][0:10]))"
      ],
      "metadata": {
        "id": "rh1g2TUjgguV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Logan Hallee (from Synthyra org) possible solution\n",
        "from torch.utils.data import Dataset as TorchDataset\n",
        "\n",
        "# To finetune a model for sequence classification you do not need to pre-embed the sequences.\n",
        "# Just need to feed the input_ids and attention_mask with the data collator. You can load the model without copying the implementation anywhere by doing this. From here you can apply lora if you'd like.\n",
        "from transformers import AutoModelForSequenceClassification, AutoConfig\n",
        "\n",
        "config = AutoConfig.from_pretrained('Synthyra/ESMplusplus_large', trust_remote_code=True, num_labels=3)\n",
        "model_classification = AutoModelForSequenceClassification.from_pretrained('Synthyra/ESMplusplus_large', trust_remote_code=True, config=config)\n",
        "tokenizer = model_classification.tokenizer\n",
        "\n",
        "# Move models to GPU and convert to half-precision (FP16)\n",
        "#model_classification = model_classification.to(device).half()\n",
        "\n",
        "# Move models to GPU and keep them in float32\n",
        "model_classification = model_classification.to(device)  # Remove .half()\n",
        "\n",
        "\n",
        "# Here's an example of a collator we use for input_ids and labels. Trainer automatically unpacks a dictionary sent to the model, so everything in \"batch\" here will go to the right place\n",
        "# This expects a PyTorch dataset class that will output a tuple of sequences and the labels you are interested in.\n",
        "def string_labels_collator_builder(tokenizer, **kwargs):\n",
        "    def _collate_fn(batch):\n",
        "        seqs = [ex[0] for ex in batch]\n",
        "        labels = torch.stack([torch.tensor(ex[1]) for ex in batch])\n",
        "        batch = tokenizer(seqs,\n",
        "                          padding='longest',\n",
        "                          truncation=False,\n",
        "                          return_tensors='pt',\n",
        "                          add_special_tokens=True)\n",
        "        batch['labels'] = labels\n",
        "        return batch\n",
        "    return _collate_fn\n",
        "\n",
        "# A class that might link up with your current workflow looks something like this\n",
        "class StringLabelDatasetFromHF(TorchDataset):\n",
        "    '''The design pattern of the code uses the PyTorch Dataset class for accessing the sequences and labels during the training loop.'''\n",
        "    def __init__(self, hf_dataset, col_name='sequence', label_col='label', **kwargs):\n",
        "        self.seqs = hf_dataset[col_name].to_numpy() # Convert to NumPy array\n",
        "        self.labels = hf_dataset[label_col].to_numpy() # Convert to NumPy array\n",
        "        self.lengths = [len(seq) for seq in self.seqs]\n",
        "\n",
        "    def avg(self):\n",
        "        return sum(self.lengths) / len(self.lengths)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.seqs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.seqs[idx]\n",
        "        label = self.labels[idx]\n",
        "        return seq, label\n",
        "\n",
        "\n",
        "torchdataset_my_train = StringLabelDatasetFromHF(my_train[0:100])\n",
        "torchdataset_my_valid = StringLabelDatasetFromHF(my_valid[0:25])\n",
        "torchdataset_my_test = StringLabelDatasetFromHF(my_test[0:25])\n",
        "data_collator = string_labels_collator_builder(tokenizer)\n"
      ],
      "metadata": {
        "id": "q2900Dw12w58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "2d42cc549c4a46cc9921c0ec5b73c401",
            "3531977bbc7c4c668a6e8defa2965cb3",
            "9370cdefc9ee44dab0fdb8bc0c610725",
            "673c0e63069844b491369ad062213de2",
            "d01817d24372455aac19d2352a20ada9",
            "c55abcc9b7e84df1b26c928333c8285b",
            "3ccdbc45a2ac41e4b51f1a496a6564bb",
            "4902f328d98f478a955b4195eeb1a5bd",
            "5ad6b9056212475ba3477f57c7a22fa9",
            "be93d69ef38548c1ae284c2aff13bff2",
            "562cf951a39e46ed873c1382c0da2b97",
            "820264867bb3425885fef92f8c74907e",
            "5d29a3aeb05846d492454926a675f023",
            "76f4446bc3e7467dba827d9a898e5c45",
            "b63dbf05679744c59750d8d1577324d6",
            "4af07581a5af4c199a54c58dd6ebacca",
            "eeb713214c0549a4938d44d84eff50fd",
            "9c12a8a6973045a6a190a1837d444a0d",
            "d5944df1f1934f2abde147c0043cf00a",
            "f805f5b1f3ed4582850dc656df1a659c",
            "6027ebebb5894d96bc13ef6b6437df22",
            "d46a40acde3a4bf7b67e6aa8dd5b7362",
            "bae510b5c18e4b908ed94b9a9ffbced6",
            "baccbf275b95457e840ed1123c1be96e",
            "a4ec381381094f58af0d7fed8af0ca61",
            "7511cbd8bfbc4e868ebd82e5f7d5faf0",
            "79bea9e802b044aebbb36fb6dcbc661a",
            "7b47d273a1d949849042fdbf016a6bbe",
            "fdcf2728a3da470081e743f07ff7e60f",
            "66ac22e522f449428d0214c9b97b205d",
            "10c9e97f34ba463fa7769434582ff60a",
            "934df197a02b428c8ef06a79db87b0eb",
            "72903e5979584010825dc4a6b5277188"
          ]
        },
        "outputId": "febcc1ae-a294-4b91-d54a-6a22216e2b11"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d42cc549c4a46cc9921c0ec5b73c401"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modeling_esm_plusplus.py:   0%|          | 0.00/42.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "820264867bb3425885fef92f8c74907e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/Synthyra/ESMplusplus_large:\n",
            "- modeling_esm_plusplus.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.30G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bae510b5c18e4b908ed94b9a9ffbced6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ESMplusplusForSequenceClassification were not initialized from the model checkpoint at Synthyra/ESMplusplus_large and are newly initialized: ['classifier.0.bias', 'classifier.0.weight', 'classifier.2.bias', 'classifier.2.weight', 'classifier.3.bias', 'classifier.3.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(torchdataset_my_train.labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuaUKzBZCaYp",
        "outputId": "c4522d8a-daf3-439c-a786-ea8d1c51f642"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Testing the custom data collator on a small batch of sequences+labels\n",
        "small_data = my_train[['sequence', 'label']][:5]\n",
        "small_pytorch_dataset = StringLabelDatasetFromHF(small_data)\n",
        "data_collator = string_labels_collator_builder(tokenizer)\n",
        "\n",
        "# Use PyTorch's DataLoader to iterate through the small dataset in batches:\n",
        "# collate_fn: argument specifies the function that will be used to collate individual data points into batches\n",
        "small_dataloader = DataLoader(small_pytorch_dataset, batch_size=2, collate_fn=data_collator)\n",
        "\n",
        "# Inspect a Batch\n",
        "for batch in small_dataloader:\n",
        "    print(batch)  # Print the contents of the batch dictionary\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NTCa5i_n6mLs",
        "outputId": "3d23fd32-790c-4e12-ead1-3186dea9bdc3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 0, 20, 17,  ...,  6,  3,  2],\n",
            "        [ 0, 20, 11,  ...,  1,  1,  1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 0])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title My original model/data loading and embedding code\n",
        "\n",
        "# Create a ProteinDataset instance with your protein sequences\n",
        "train_dataset = ProteinDataset(list(my_train['sequence']))\n",
        "test_dataset = ProteinDataset(list(my_test['sequence']))\n",
        "valid_dataset = ProteinDataset(list(my_valid['sequence']))\n",
        "\n",
        "# Initialize the model for protein embedding\n",
        "# Tokenizer is already initialized in this class (self.tokenizer = EsmSequenceTokenizer())\n",
        "model_embedding = ESMplusplus_600M(num_labels=3)\n",
        "#tokenizer = model_embedding.tokenizer\n",
        "\n",
        "# Create a new ESMplusplusForSequenceClassification model\n",
        "# This model is separate from the model_embedding\n",
        "model_classification_v2 = ESMplusplusForSequenceClassification.from_pretrained_esm(\"600\")\n",
        "\n",
        "# Load the state dict of the base model (without the classification head) to the new model\n",
        "model_classification.load_state_dict(model_embedding.state_dict(), strict=False)\n",
        "\n",
        "# # Move models to GPU and convert to half-precision (FP16)\n",
        "# model_embedding = model_embedding.to(device).half()\n",
        "# model_classification = model_classification.to(device).half()\n",
        "\n",
        "# Move models to GPU and keep them in float32\n",
        "model_embedding = model_embedding.to(device)  # Remove .half()\n",
        "model_classification = model_classification.to(device)  # Remove .half()\n",
        "\n",
        "\n",
        "def get_classification_dataset(model, dataset, labels, max_len=550, batch_size=16, pooling_type=\"mean\"):\n",
        "    \"\"\"Generate embeddings and create classification dataset.\n",
        "       The internal DataLoader within embed_dataset is already handling the batching of data during embedding generation.\n",
        "    \"\"\"\n",
        "    embeddings_dict = model.embed_dataset(\n",
        "        dataset,\n",
        "        max_len=max_len,\n",
        "        batch_size=batch_size,\n",
        "        pooling_type=pooling_type,\n",
        "        full_precision=True,\n",
        "    )\n",
        "\n",
        "    # Create a dictionary to store data\n",
        "    dataset_dict = {'inputs_embeds': [], 'labels': []}\n",
        "    for i in range(len(dataset)):  # Iterate by index\n",
        "        sequence = dataset[i]  # Get sequence using __getitem__\n",
        "        embedding = embeddings_dict.get(sequence)\n",
        "        if embedding is not None:\n",
        "            dataset_dict['inputs_embeds'].append(embedding)  # Append to list\n",
        "            dataset_dict['labels'].append(labels[i])       # Append to list\n",
        "        else:\n",
        "            print(f\"Warning: Sequence '{sequence}' not found in embeddings_dict. Skipping...\")\n",
        "\n",
        "    return Dataset.from_dict(dataset_dict)\n",
        "\n",
        "\n",
        "# Create TensorDatasets with embeddings and labels using get_classification_dataset\n",
        "train_dataset_classification = get_classification_dataset(model_embedding, list(my_train['sequence']), list(my_train['label']))\n",
        "test_dataset_classification = get_classification_dataset(model_embedding, list(my_test['sequence']), list(my_test['label']))\n",
        "valid_dataset_classification = get_classification_dataset(model_embedding, list(my_valid['sequence']), list(my_valid['label']))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "T6L6oYMwLSjR",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset_classification)\n",
        "print(train_dataset_classification[0])\n",
        "print(train_dataset_classification.features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY7iCMG51i3j",
        "outputId": "c4e1694d-dea8-4ce8-f590-6453031ef8dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['inputs_embeds', 'labels'],\n",
            "    num_rows: 2338\n",
            "})\n",
            "{'inputs_embeds': [-0.023973623290657997, -0.04354223236441612, -0.004743195604532957, -0.02861812897026539, -0.0008747765677981079, -0.03435741364955902, 0.025471772998571396, -0.006187583319842815, 0.007463967427611351, 0.029759440571069717, -0.0021257500629872084, 0.018827270716428757, -0.012098248116672039, -0.02671876549720764, 0.03714583441615105, -0.031489357352256775, -0.0013180127134546638, -0.002125516999512911, 0.016997428610920906, 0.05265428125858307, 0.064813531935215, -0.00753829488530755, -0.011604984290897846, 0.014580518007278442, -0.012080320157110691, -0.03716570883989334, 0.027980389073491096, 0.006632362492382526, 0.038738857954740524, -0.0024991247337311506, 0.028428370133042336, 0.020869024097919464, -0.042663101106882095, 0.02030995674431324, -0.04061656817793846, 0.03700200095772743, -0.01907176710665226, -0.031393397599458694, 0.026571379974484444, -0.012965292669832706, -0.040591657161712646, 0.023525603115558624, -0.04455012083053589, -0.0008917442173697054, 0.012737688608467579, 0.020247407257556915, -0.029686937108635902, 0.03128818795084953, 0.0039086295291781425, -0.043375492095947266, -0.015604847110807896, -0.009442339651286602, -0.015126640908420086, -0.017832348123192787, -0.04110534489154816, 0.018219925463199615, -0.05925826355814934, 0.02533515729010105, -0.048445433378219604, 0.0034390429500490427, 0.05478684604167938, -0.057778045535087585, 0.012432430870831013, -0.005157222039997578, -0.0034574647434055805, -0.04550377279520035, 0.004863468464463949, -0.015631239861249924, -0.023836057633161545, -0.04316774383187294, -0.005634769797325134, -0.04648671671748161, 0.03114415891468525, 0.018491797149181366, -0.02680835872888565, -0.00011864653060911223, 0.01315809041261673, -0.060485392808914185, 0.020106598734855652, -0.0018057883717119694, -0.03196564316749573, -0.024616604670882225, -0.04350772500038147, 0.03163086995482445, -0.0016316327964887023, 0.012228625826537609, 0.05046107620000839, 0.015843015164136887, 0.03272391855716705, 0.02662699855864048, 0.0025428871158510447, -0.00337977334856987, -0.004214993212372065, -0.01760319620370865, 0.007710867561399937, -0.01200437918305397, -0.018767692148685455, -0.0005905897123739123, -0.007958881556987762, -0.0169216301292181, -0.009817484766244888, 0.0015560680767521262, 0.05704677477478981, -0.024747334420681, 0.0003018778224941343, 0.04563073813915253, -0.003029514802619815, 0.039037030190229416, 0.022840019315481186, 0.00041971521568484604, 0.007143460214138031, -0.042240992188453674, 0.026743410155177116, -0.0025893589481711388, 0.04325896129012108, -0.015415539965033531, -0.011749479919672012, 0.030453216284513474, 0.014997977763414383, -0.03148489072918892, 0.03128346800804138, 0.010392285883426666, -0.06271106004714966, 0.032006435096263885, -0.040801968425512314, 0.06614267826080322, -0.0361887663602829, -0.02842567302286625, 0.032584961503744125, 0.0018492278177291155, 0.02026449702680111, -0.007835467346012592, -0.06074509769678116, -0.004740296397358179, 0.040081724524497986, 0.006379701662808657, -0.019795846194028854, -0.020535672083497047, 0.002816807711496949, -0.0028539958875626326, -0.009448166005313396, 0.03134763240814209, 0.0071585820987820625, 0.018665190786123276, 0.02161649987101555, 0.004259816836565733, 0.017890632152557373, 0.022032175213098526, 0.025721745565533638, 0.04598185047507286, 0.035377275198698044, -0.01736627146601677, -0.012500017881393433, 0.00261451187543571, 0.03632649779319763, 0.04260290041565895, 0.014339336194097996, 0.03841990977525711, 0.042886439710855484, -0.054653190076351166, 0.013011125847697258, 0.03350485488772392, 0.02960369363427162, 0.040511272847652435, -0.014092797413468361, 0.03213940188288689, -0.018170688301324844, 0.013115647248923779, 0.0016890981933102012, 0.026022881269454956, 0.017047308385372162, -0.033087871968746185, 0.029640529304742813, -0.0438602939248085, -0.015649795532226562, 0.00835887249559164, -0.07676597684621811, -0.0058646416291594505, 0.02679908648133278, 0.005596267059445381, -0.01608867570757866, -0.02379915677011013, -0.030625447630882263, -0.011315924115478992, 0.052355311810970306, 0.020973490551114082, -0.014414604753255844, 0.03618849068880081, -0.04536385089159012, -0.02789245918393135, 0.059661198407411575, -0.001041519339196384, 0.021286694332957268, -0.052303194999694824, 0.035360269248485565, -0.031198544427752495, 0.00234138872474432, -0.033122751861810684, 0.030996255576610565, 0.006328079383820295, -0.015200119465589523, -0.014975030906498432, -0.017693743109703064, -0.03108653426170349, -0.04151363670825958, -0.03909185901284218, -0.013163202442228794, 0.0007038245676085353, 0.05288698524236679, 0.02392852120101452, -0.006305878981947899, 0.03275733441114426, -0.00364787713624537, 0.010651573538780212, -0.02116873487830162, -0.04489947855472565, 0.002203436102718115, -0.008647358044981956, 0.01453996542841196, 0.053539201617240906, -2.5516676032566465e-05, -0.00617879768833518, -0.011827688664197922, 0.00795690342783928, 0.06923801451921463, -0.005398737732321024, 0.03625025600194931, -0.047608520835638046, 0.004053874872624874, 0.010030665434896946, -0.01677853614091873, -0.008561039343476295, -0.04410901293158531, 0.011972078122198582, 0.0063498192466795444, 0.017707746475934982, 0.17604243755340576, 0.03525400161743164, -0.008562407456338406, 0.022159529849886894, -0.006759922951459885, 0.01686241291463375, -0.037725601345300674, 0.004113573115319014, 0.017356712371110916, -0.005410326179116964, 0.07852350920438766, -0.015032628551125526, 0.0443497896194458, -0.007502807769924402, 0.029431581497192383, -0.0027908787596970797, -0.0390755794942379, -0.01679372414946556, -0.03599896654486656, 0.026460932567715645, 0.03184305503964424, -0.011652897112071514, 0.0031999705825001, -0.026266062632203102, -0.03020387329161167, -0.18084782361984253, -0.007948415353894234, 0.036137085407972336, 0.021086515858769417, 0.04076800122857094, -0.011302550323307514, -0.01882057636976242, 0.027844415977597237, -0.1004764512181282, 0.026986731216311455, -0.01683582179248333, 0.006627381779253483, -0.03556763753294945, -0.05359483137726784, -0.014131395146250725, 0.003140856511890888, -0.01433749683201313, -0.0050557320937514305, 0.01218421570956707, 0.0029067934956401587, -0.021375292912125587, -0.003932422026991844, 0.020818494260311127, -0.04310788959264755, 0.007682539988309145, -0.0050302171148359776, 0.051527928560972214, 0.048293337225914, 0.053629420697689056, 0.006344780325889587, 0.011124405078589916, -0.007744074333459139, 0.02765541337430477, 0.011540021747350693, 0.012381207197904587, -0.002330886200070381, -0.018674669787287712, -0.023303188383579254, -0.044315584003925323, -0.003481833962723613, -0.0485956072807312, 0.025834837928414345, 0.028344687074422836, 0.012416399084031582, 0.0005630278028547764, -0.010568835772573948, -0.010257896035909653, -0.030180178582668304, -0.023893723264336586, 0.011573472991585732, 0.007015497423708439, -0.02071811631321907, 0.06910243630409241, -0.04097632318735123, 0.008518507704138756, 0.02223980613052845, -0.00523431645706296, 0.03278154134750366, -0.019590508192777634, 0.05924297124147415, 0.007780413143336773, 0.018625669181346893, 0.01325775682926178, -0.0008911401964724064, 0.0018078626599162817, 0.018826737999916077, 0.009590629488229752, 0.04325929656624794, -0.0049257902428507805, 0.013800757005810738, 0.01662375032901764, 0.01523144543170929, -0.008361103013157845, -0.2709629237651825, 0.06234635040163994, 0.024753684177994728, 0.035840559750795364, -0.004322938621044159, -0.00860690325498581, -0.000716131879016757, 0.03567001596093178, 0.0007778526633046567, -0.0275861993432045, -0.029442118480801582, 0.04715867340564728, 0.02645498514175415, -0.022903846576809883, 0.037735722959041595, 0.026321779936552048, 0.04909004271030426, -0.005865999963134527, -0.05870605260133743, -0.009222929365932941, -0.00024973732070066035, -0.02255168929696083, -0.005401287693530321, -0.010418086312711239, 0.010762800462543964, -0.027429666370153427, -0.038373738527297974, -0.0032973913475871086, -0.04320386424660683, -0.017311496660113335, -0.04281824827194214, -0.04937693849205971, 0.04406668245792389, 0.01625128649175167, -0.0458570271730423, -0.010054011829197407, -0.03970583528280258, 0.031275905668735504, 0.002612328389659524, -0.06485394388437271, -0.026117730885744095, -0.06929808855056763, 0.003705065930262208, 0.02128412015736103, -0.02984755113720894, -0.031068360432982445, 0.04380737990140915, 0.001551617169752717, 0.03926197811961174, 0.044935472309589386, -0.006214262451976538, 0.03952967748045921, 0.01016779150813818, 0.013106376864016056, 0.006757017690688372, -0.019775250926613808, 0.005314420908689499, -0.013717989437282085, 0.00888094212859869, -0.010851350612938404, -0.038761310279369354, 0.006629688199609518, 0.0037024449557065964, -0.0165287833660841, -0.05080598592758179, -0.011839841492474079, 0.05574304983019829, 0.0048826769925653934, 0.03785315528512001, -0.028219399973750114, 0.01202201284468174, -0.0039513916708528996, -0.02421613782644272, 0.01466428767889738, 0.003549885470420122, -0.041186410933732986, -0.017695492133498192, 0.03200165182352066, 0.05570108816027641, 0.01769508421421051, 0.0012527527287602425, -0.032459601759910583, -0.026885470375418663, 0.025025688111782074, 0.005724795628339052, 0.019176194444298744, 0.020732756704092026, 0.003312344430014491, -0.019344372674822807, -0.032594963908195496, 0.002329441485926509, -0.013257261365652084, -2.5798264687182382e-05, -0.02343592792749405, -0.00216125906445086, 0.015419824048876762, 0.017699414864182472, -0.0159841887652874, 0.01330697163939476, 0.014806420542299747, -0.03169365972280502, -0.03020371124148369, 0.0014326028758659959, 0.005556293297559023, -0.024960314854979515, -0.015991000458598137, -0.01803545095026493, -0.042077161371707916, -0.007513884920626879, -0.06424591690301895, 0.05303895100951195, -0.002323445165529847, -0.028878889977931976, 0.0286577045917511, -0.04584740102291107, 0.01380923017859459, -0.02189750038087368, 0.012944416143000126, -0.003483092412352562, 0.024073971435427666, -0.03939829021692276, 0.0004791216051671654, 0.03353600203990936, -0.011886942200362682, -0.021967215463519096, -0.01606171578168869, -0.0156266987323761, -0.0242193341255188, 0.03740151971578598, -0.02225566655397415, 0.017997803166508675, -0.015775704756379128, -0.04518207907676697, 0.004857372958213091, 0.03933090716600418, -0.026580404490232468, -0.020028131082654, 0.003941805101931095, 0.009048380888998508, -0.03563997894525528, 0.027632195502519608, -0.025121506303548813, 0.0030145635828375816, 0.003082376206293702, -0.007294367998838425, -0.01223684661090374, 0.014498146250844002, -0.030442578718066216, 0.03253374993801117, 0.03209392726421356, 0.034141555428504944, 0.047588225454092026, -0.01379871554672718, -0.014881226234138012, -0.03134123235940933, 0.025794707238674164, -0.016653457656502724, 0.012134806253015995, 0.033258382230997086, 0.03115265816450119, -0.038366369903087616, 0.03762437030673027, 0.004636636935174465, -0.02336888574063778, 0.0006562418420799077, 0.07021112740039825, -0.07892638444900513, 0.010433591902256012, -0.05538038909435272, 0.015471682883799076, 0.002055748598650098, -0.010854851454496384, -0.04526381194591522, 0.05027053877711296, -0.02856741100549698, -0.011061768978834152, 0.016829146072268486, -0.005758127197623253, 0.015705585479736328, 0.041658952832221985, 0.02164786495268345, -0.017308248206973076, 0.007732804398983717, 0.01637152023613453, -0.021526753902435303, -0.0341588519513607, 0.03900088369846344, 0.01592150889337063, 0.5849787592887878, 0.042230214923620224, 0.016688788309693336, 0.04119541496038437, -0.03079276718199253, 0.007762022316455841, -0.011662864126265049, 0.0008916946244426072, -8.910949873097707e-06, 0.02595897950232029, -0.01470464188605547, -0.0022336672991514206, -0.01704993098974228, 0.003628841135650873, 0.04222901538014412, -0.004159162286669016, -0.0156182162463665, 0.0073975976556539536, 0.025306299328804016, 0.003222597297281027, 0.014064116403460503, -0.021870942786335945, 0.01729544810950756, 0.0007572364993393421, 0.05127537623047829, 0.059607893228530884, -0.03639751672744751, -0.014753326773643494, 0.00912599265575409, -0.014208542183041573, -0.018716728314757347, 0.04626050218939781, -0.019936438649892807, 0.007811823394149542, 0.03166019171476364, 0.02709132805466652, -0.009172237478196621, -0.00963586661964655, -0.052708592265844345, -0.01263118814677, -0.003456075908616185, 0.012289285659790039, -0.015012741088867188, 0.008851459249854088, 0.017267068848013878, 0.029963329434394836, 0.00047420768532902, 0.026256050914525986, 0.03741159290075302, 0.019846590235829353, -0.022232461720705032, 0.029431574046611786, 0.020626716315746307, 0.020258676260709763, -0.014017443172633648, -0.04678377881646156, -0.011400816030800343, 4.445626018423354e-06, 0.01706979051232338, 0.012076794169843197, 0.019223159179091454, 0.07930679619312286, -0.02814936637878418, -0.007645139936357737, 0.05513651296496391, -0.02632388100028038, -0.02838955447077751, 0.01858571544289589, 0.02549847401678562, -0.005423758178949356, -0.01802545227110386, 0.0331510528922081, -0.02622559852898121, 0.023655060678720474, -0.003723472822457552, 0.0636046826839447, -0.0004089715948794037, 0.030077440664172173, 0.03347160294651985, 0.02188972383737564, -0.04622003063559532, -0.016935225576162338, 0.0007255467935465276, 0.020362727344036102, 0.01975017786026001, 0.006859340704977512, 0.003022367600351572, -0.021359477192163467, 0.022110948339104652, 0.019687853753566742, 0.021781591698527336, -0.013459249399602413, -0.016252653673291206, 0.019441144540905952, 0.02012461982667446, 0.014956002123653889, -0.049934808164834976, 0.00958313513547182, -0.19567953050136566, 0.014786270447075367, -0.0017427459824830294, 0.030257878825068474, 0.014565489254891872, 0.011348698288202286, 0.01447734422981739, 0.016491739079356194, 0.04321734234690666, 0.0018378498498350382, 0.016010815277695656, 0.012926208786666393, -0.025988271459937096, 0.04128395766019821, 0.01849706843495369, -0.029416367411613464, -0.006865829695016146, 0.01949961483478546, -0.010071747936308384, 0.011870298534631729, 0.01028634887188673, -0.0011487490264698863, 0.023672543466091156, -0.010567864403128624, -0.010286327451467514, -0.0014201448066160083, 0.040764790028333664, -0.0006523560150526464, -0.038899846374988556, 0.026318401098251343, -0.012223649770021439, -0.016646219417452812, -0.011716609820723534, 0.02821139432489872, -0.04229817911982536, -0.008755193091928959, 0.005444489885121584, 0.03087877854704857, 0.0014287122758105397, 0.038775090128183365, 0.002231849357485771, 0.040440864861011505, 0.03294313699007034, -0.05312281474471092, -0.006943363230675459, -0.017111266031861305, -0.04059620574116707, 0.022526657208800316, 0.0004514606262091547, 0.038755789399147034, -0.031059356406331062, 0.0084476787596941, 0.05160956829786301, 0.019364936277270317, -0.03031667321920395, -0.02590988390147686, 0.008422000333666801, -0.32361501455307007, 0.020514724776148796, 0.03426327556371689, -0.009248756803572178, -0.013161811977624893, -0.02126474864780903, 0.01960570365190506, 0.03228825330734253, 0.0038165180012583733, -0.04764927178621292, -0.0009716283529996872, 0.03627150505781174, 0.011686781421303749, 0.013828120194375515, 0.04841027036309242, 0.007508070673793554, -0.04372008144855499, 0.005649607162922621, 0.03230924531817436, -0.029890665784478188, -0.009695455431938171, 0.012853407301008701, -0.09131466597318649, -0.07762934267520905, 0.006750680040568113, -0.026105651631951332, -0.03884639963507652, -0.03311648964881897, 0.038402117788791656, -0.03386060148477554, -0.0025266786105930805, -0.020983757451176643, -0.022414468228816986, 0.007444765884429216, -0.017505884170532227, -0.007691564504057169, -0.004863210022449493, 0.010121827013790607, -0.001610842882655561, -0.0010590573074296117, 0.05588860437273979, 0.03889573737978935, 0.01663653925061226, 0.02657599374651909, -0.011116011999547482, -0.03686125576496124, -0.04043738543987274, -0.014434795826673508, 0.023805126547813416, 0.01627282053232193, 0.03506908193230629, 0.008410381153225899, 0.013240628875792027, 0.045723553746938705, 0.025759253650903702, -0.02486218884587288, 0.03341927379369736, -0.010032028891146183, 0.01675988733768463, 0.0026196043472737074, 0.005688680801540613, 0.027530234307050705, -0.02308766357600689, 0.020969068631529808, 0.022477436810731888, -0.019536258652806282, 0.011212209239602089, 0.052612245082855225, -0.03164256736636162, -0.008906290866434574, -0.009342866018414497, 0.0054806857369840145, 0.03714854270219803, -0.029276898130774498, 0.009923345409333706, -0.01568700559437275, -0.022055763751268387, -0.02360576204955578, -0.011777290143072605, 0.019038300961256027, -0.02850697748363018, -0.0031858105212450027, 0.01173725537955761, 0.011649351567029953, 0.04692838340997696, -0.06453957408666611, 0.016174256801605225, 0.014300091192126274, 0.0068990085273981094, 0.031942836940288544, 0.025609400123357773, 0.018368050456047058, 0.03487544134259224, -0.04100165516138077, -0.03426915779709816, 0.04507110267877579, -0.046306855976581573, -0.07395292073488235, -0.02083737775683403, -0.025672506541013718, -0.03416996821761131, 0.010969165712594986, 0.004851249046623707, 0.021548617631196976, 0.047902025282382965, -0.02077464945614338, 0.036891836673021317, -0.0014251845423132181, 0.0006822425057180226, -0.008004937320947647, 0.003938587848097086, -0.02387510985136032, 0.029820455238223076, -0.02228289283812046, -0.005245001055300236, -0.029389692470431328, -0.016178322955965996, 0.03316792845726013, -0.004025291185826063, 0.0197225883603096, -0.048343028873205185, -0.029540028423070908, 0.051313575357198715, 0.00845952145755291, -0.026959434151649475, 0.0016672916244715452, -0.0017517078667879105, 0.026558928191661835, -0.005505539942532778, -0.012781010940670967, 0.005015529692173004, 0.0286096278578043, 0.03410100191831589, -0.01505734957754612, 0.002459297887980938, 0.0576263889670372, 0.005731699522584677, -0.07876075059175491, 0.01938977651298046, -0.03595894202589989, -0.0150035684928298, 0.014028646051883698, 0.05392136424779892, 0.01662265509366989, -0.06368608772754669, 0.029401736333966255, -0.00490760849788785, 0.009209553711116314, 0.0026290134992450476, 0.03581619635224342, -0.022255491465330124, 0.0021097722928971052, 0.03437979146838188, 0.04104302451014519, 0.0045355199836194515, 0.019037630409002304, -0.015535612590610981, -0.0017318016616627574, 0.004925084766000509, -0.04471435397863388, -0.03950436785817146, -0.05145666375756264, -0.02162005938589573, 0.018631819635629654, -0.0007069007842801511, -0.009272301569581032, -0.037322308868169785, -0.010559587739408016, 0.034288808703422546, 0.05709151178598404, 0.01976787857711315, 0.021612651646137238, 0.04004841297864914, -0.013262446038424969, 0.007340926676988602, -0.0005808819551020861, 0.0024510992225259542, 0.009901664219796658, -0.026996320113539696, -0.06430035084486008, -0.03257068619132042, 0.0456569567322731, -0.041184037923812866, -0.004956224001944065, 0.029956502839922905, 0.023300260305404663, 0.012993195094168186, -0.035353876650333405, -0.003340037539601326, 0.012228980660438538, -0.03906191885471344, 0.03437735140323639, -0.0032704828772693872, 0.0010339318541809916, -0.03670547902584076, -0.031583741307258606, 0.032694261521101, -0.02509654127061367, -0.0705702155828476, 0.021271320059895515, 0.009033841080963612, -0.01518265437334776, -0.018947172909975052, 0.020485781133174896, -0.010678475722670555, -0.01834227330982685, -0.01125081442296505, 0.027233529835939407, 0.021741094067692757, -0.020874354988336563, -0.0038344745989888906, -0.020079491659998894, -0.02177288569509983, 0.02795347198843956, -0.042136285454034805, 0.011559301987290382, 0.020352916792035103, -0.01311791967600584, -0.018280521035194397, -0.010344013571739197, 0.0480266809463501, 0.005058169364929199, 0.029975226148962975, -0.008081096224486828, -0.013777952641248703, 0.014439522288739681, -0.014110791496932507, 0.0009853871306404471, 0.009602290578186512, -0.0020120213739573956, -0.011492712423205376, -0.000574537378270179, 0.016666285693645477, -0.011231141164898872, 0.028177909553050995, -0.00681541720405221, -0.014283396303653717, -0.06198517978191376, -0.009745487943291664, -0.029215088114142418, 0.03095434419810772, -0.005921740550547838, 0.011342236772179604, -0.0445048063993454, 0.006441878620535135, -0.026860198006033897, -0.06961475312709808, -0.019663603976368904, 0.002533563179895282, 0.008486277423799038, -0.030569737777113914, -0.03321775421500206, -0.02255064621567726, -0.04656016826629639, -0.032875675708055496, -0.0020296149887144566, 0.020167263224720955, 0.0786314532160759, -0.03445008024573326, 0.06457135826349258, -0.03480733931064606, 3.4516764571890235e-05, -0.010103864595293999, -0.027071798220276833, 0.015424448996782303, 0.000896092620678246, 0.021517805755138397, -0.047077279537916183, -0.002919884165748954, -0.033006634563207626, -0.01335968729108572, 0.014618071727454662, 0.01335916668176651, -0.02101314440369606, 0.01718980073928833, 0.04226189851760864, 0.008210954256355762, 0.02065345272421837, 0.0002707040694076568, -0.00030837065423838794, 0.0003972587001044303, -0.014626999385654926, 0.025657866150140762, -0.004518548026680946, -0.04335002228617668, 0.040776655077934265, -0.031039681285619736, -0.011978771537542343, -0.02153605781495571, -0.029891692101955414, 0.018937043845653534, 0.025380317121744156, -0.05841286852955818, 0.004830196965485811, -0.003993515390902758, -0.013096517883241177, 0.033131130039691925, -0.02904759906232357, -0.026129310950636864, -0.04766958951950073, -0.018165793269872665, -0.01938312128186226, -0.02842460758984089, 0.027012428268790245, -0.03166933357715607, 0.018481917679309845, -0.010644454509019852, 0.05730433389544487, -0.01676296815276146, -0.03934285044670105, 0.010238098911941051, 0.026449698954820633, 0.01160301174968481, -0.03721311315894127, -0.0053704530000686646, -0.01718721352517605, -0.004725602921098471, -0.03383199870586395, -0.01707613095641136, 0.002331478288397193, 0.041667401790618896, 0.036399535834789276, -0.015159005299210548, 0.026551498100161552, -0.002655012533068657, 0.029905755072832108, -0.0016891679260879755, -0.028788305819034576, -0.018995217978954315, 0.015827642753720284, 0.0009096275898627937, 0.007499040104448795, -0.01790560595691204, 0.022538580000400543, 0.01232601422816515, 0.011388842016458511, -0.004553663078695536, -0.012597533874213696, -0.02358086220920086, 0.013204818591475487, -0.010098270140588284, -0.025065952911973, -0.024552442133426666, 0.029467588290572166, 0.0012794361682608724, 0.0046224892139434814, 0.008916337974369526, -0.07397076487541199, 0.04112093895673752, 0.009327073581516743, -0.019335508346557617, -0.022457562386989594, 0.025024887174367905, -0.031097494065761566, -0.021769938990473747, 0.016030021011829376, 0.04138363152742386, 0.00033323621028102934, -0.11951572448015213, 0.00762978894636035, -0.025578107684850693, 0.025653747841715813, 0.017824526876211166, -0.02421068400144577, 0.04065333306789398, 0.03304562345147133, -0.010767528787255287, -0.3930058181285858, 0.0020131065975874662, 0.009768493473529816, 0.004401803016662598, -0.03914091736078262, -0.031600482761859894, -0.06039272993803024, 0.011621948331594467, -0.03316529467701912, 0.007107970770448446, -0.016616424545645714, -0.012143618427217007, -0.01882796920835972, -0.02661745995283127, -0.0399741567671299, 0.02495506778359413, 0.009502533823251724, 0.023312775418162346, -0.01483589131385088, 0.03273526206612587, -0.011746464297175407, 0.0203620083630085, 0.03859797492623329, -0.015570750460028648, -0.0014653519028797746, 0.010848027653992176, 0.04695482552051544, 0.041920989751815796, -0.04635418951511383, -0.06674155592918396, -0.03166165575385094, -0.012961141765117645, -0.015750212594866753, -0.05342858284711838, 0.07412116974592209, 0.00988814327865839, 0.004782188218086958, 0.033013563603162766, 0.005712945479899645, 0.022408856078982353, 0.031799349933862686, -0.0010041710920631886, 0.004383146297186613, 0.014325694181025028, 0.015618163160979748, 0.030591599643230438, 0.006343426648527384, -0.6162088513374329, 0.041204165667295456, 0.052732646465301514, 0.0091498252004385, -0.0503961406648159, 0.05209236592054367, 0.007099459413439035, 0.02385171316564083, 0.026116035878658295, -0.023354800418019295, -0.02511952631175518, 0.013878540135920048, -0.018157297745347023, 0.004234577529132366, 0.036433927714824677, 0.0319741927087307, 0.005742316599935293, 0.008948140777647495, 0.01034616306424141, 0.004659814760088921, 0.005317851901054382, -0.010996158234775066, 0.05137130245566368, 0.01389306876808405, 0.059429530054330826, -0.012797628529369831, 0.004654861520975828, -0.026699671521782875, -0.030580995604395866, 0.05263639613986015, -0.015936782583594322, 0.0043012541718780994, -0.018004318699240685, -0.012355377897620201, -0.0027279979549348354, 0.026677042245864868, 0.022167973220348358, 0.09054021537303925, 0.009398876689374447, -0.0005096765235066414, -0.020921852439641953, -0.04232770577073097, 0.009609551168978214, 0.05235486850142479, -0.006603296846151352, -0.04333863779902458, -0.012249216437339783, 0.009194384329020977, 0.010159507393836975, 0.0005680583999492228, 0.03827515244483948, -0.002719202311709523, -0.003489011200144887, -0.057353466749191284, -0.006153381895273924, 0.06509438902139664, 0.007848657667636871, 0.003715143073350191, 0.014576158486306667, 0.015360998921096325, 0.0214821957051754], 'labels': 0}\n",
            "{'inputs_embeds': Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None), 'labels': Value(dtype='int64', id=None)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Print the model's architecture__ to identify the layers in the model_classification that you want LoRA to adapt."
      ],
      "metadata": {
        "id": "Ff2Gb-pZHWfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_classification)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vN4AJMTR70Mp",
        "outputId": "7e33182b-190e-46b8-dde1-d96ff07a7928"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ESMplusplusForSequenceClassification(\n",
            "  (embed): Embedding(64, 1152)\n",
            "  (transformer): TransformerStack(\n",
            "    (blocks): ModuleList(\n",
            "      (0-35): 36 x UnifiedTransformerBlock(\n",
            "        (attn): MultiHeadAttention(\n",
            "          (layernorm_qkv): Sequential(\n",
            "            (0): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)\n",
            "            (1): Linear(in_features=1152, out_features=3456, bias=False)\n",
            "          )\n",
            "          (out_proj): Linear(in_features=1152, out_features=1152, bias=False)\n",
            "          (q_ln): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)\n",
            "          (k_ln): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)\n",
            "          (rotary): RotaryEmbedding()\n",
            "        )\n",
            "        (ffn): Sequential(\n",
            "          (0): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Linear(in_features=1152, out_features=6144, bias=False)\n",
            "          (2): SwiGLU()\n",
            "          (3): Linear(in_features=3072, out_features=1152, bias=False)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (sequence_head): Sequential(\n",
            "    (0): Linear(in_features=1152, out_features=1152, bias=True)\n",
            "    (1): GELU(approximate='none')\n",
            "    (2): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)\n",
            "    (3): Linear(in_features=1152, out_features=64, bias=True)\n",
            "  )\n",
            "  (ce_loss): CrossEntropyLoss()\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=2304, out_features=4608, bias=True)\n",
            "    (1): GELU(approximate='none')\n",
            "    (2): LayerNorm((4608,), eps=1e-05, elementwise_affine=True)\n",
            "    (3): Linear(in_features=4608, out_features=3, bias=True)\n",
            "  )\n",
            "  (mse): MSELoss()\n",
            "  (ce): CrossEntropyLoss()\n",
            "  (bce): BCEWithLogitsLoss()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_classification_v2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8B3APAf2fEJ4",
        "outputId": "6ef64e7c-039e-4d0b-b8ee-4907cbf87975"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ESMplusplusForMaskedLM(\n",
            "  (embed): Embedding(64, 1152)\n",
            "  (transformer): TransformerStack(\n",
            "    (blocks): ModuleList(\n",
            "      (0-35): 36 x UnifiedTransformerBlock(\n",
            "        (attn): MultiHeadAttention(\n",
            "          (layernorm_qkv): Sequential(\n",
            "            (0): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)\n",
            "            (1): Linear(in_features=1152, out_features=3456, bias=False)\n",
            "          )\n",
            "          (out_proj): Linear(in_features=1152, out_features=1152, bias=False)\n",
            "          (q_ln): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)\n",
            "          (k_ln): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)\n",
            "          (rotary): RotaryEmbedding()\n",
            "        )\n",
            "        (ffn): Sequential(\n",
            "          (0): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)\n",
            "          (1): Linear(in_features=1152, out_features=6144, bias=False)\n",
            "          (2): SwiGLU()\n",
            "          (3): Linear(in_features=3072, out_features=1152, bias=False)\n",
            "        )\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (sequence_head): Sequential(\n",
            "    (0): Linear(in_features=1152, out_features=1152, bias=True)\n",
            "    (1): GELU(approximate='none')\n",
            "    (2): LayerNorm((1152,), eps=1e-05, elementwise_affine=True)\n",
            "    (3): Linear(in_features=1152, out_features=64, bias=True)\n",
            "  )\n",
            "  (ce_loss): CrossEntropyLoss()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Using Regex Wildcards with LoRA to select target modules__\n",
        "\n",
        "While LoRA itself doesn't directly support regex wildcards in the target_modules parameter, you can achieve a similar effect by programmatically generating the list of target modules using regex matching."
      ],
      "metadata": {
        "id": "FQiNtai1Lj6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the regex pattern to match desired layers (excluding LayerNorm - ffn.0)\n",
        "pattern = r\"transformer\\.blocks\\.\\d+\\.(attn\\.layernorm_qkv\\.1|attn\\.out_proj|ffn\\.[13])\"\n",
        "\n",
        "\n",
        "# Get all matching module names\n",
        "target_modules = [\n",
        "    name\n",
        "    for name, module in model_classification.named_modules() # iterate through all modules and their names.\n",
        "    if re.fullmatch(pattern, name)\n",
        "]\n",
        "print(f'Target modules for LORA: {target_modules}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I29KrCvJLkGi",
        "outputId": "62060e92-1cc3-4fc6-cf8f-20e5b6b909a2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target modules for LORA: ['transformer.blocks.0.attn.layernorm_qkv.1', 'transformer.blocks.0.attn.out_proj', 'transformer.blocks.0.ffn.1', 'transformer.blocks.0.ffn.3', 'transformer.blocks.1.attn.layernorm_qkv.1', 'transformer.blocks.1.attn.out_proj', 'transformer.blocks.1.ffn.1', 'transformer.blocks.1.ffn.3', 'transformer.blocks.2.attn.layernorm_qkv.1', 'transformer.blocks.2.attn.out_proj', 'transformer.blocks.2.ffn.1', 'transformer.blocks.2.ffn.3', 'transformer.blocks.3.attn.layernorm_qkv.1', 'transformer.blocks.3.attn.out_proj', 'transformer.blocks.3.ffn.1', 'transformer.blocks.3.ffn.3', 'transformer.blocks.4.attn.layernorm_qkv.1', 'transformer.blocks.4.attn.out_proj', 'transformer.blocks.4.ffn.1', 'transformer.blocks.4.ffn.3', 'transformer.blocks.5.attn.layernorm_qkv.1', 'transformer.blocks.5.attn.out_proj', 'transformer.blocks.5.ffn.1', 'transformer.blocks.5.ffn.3', 'transformer.blocks.6.attn.layernorm_qkv.1', 'transformer.blocks.6.attn.out_proj', 'transformer.blocks.6.ffn.1', 'transformer.blocks.6.ffn.3', 'transformer.blocks.7.attn.layernorm_qkv.1', 'transformer.blocks.7.attn.out_proj', 'transformer.blocks.7.ffn.1', 'transformer.blocks.7.ffn.3', 'transformer.blocks.8.attn.layernorm_qkv.1', 'transformer.blocks.8.attn.out_proj', 'transformer.blocks.8.ffn.1', 'transformer.blocks.8.ffn.3', 'transformer.blocks.9.attn.layernorm_qkv.1', 'transformer.blocks.9.attn.out_proj', 'transformer.blocks.9.ffn.1', 'transformer.blocks.9.ffn.3', 'transformer.blocks.10.attn.layernorm_qkv.1', 'transformer.blocks.10.attn.out_proj', 'transformer.blocks.10.ffn.1', 'transformer.blocks.10.ffn.3', 'transformer.blocks.11.attn.layernorm_qkv.1', 'transformer.blocks.11.attn.out_proj', 'transformer.blocks.11.ffn.1', 'transformer.blocks.11.ffn.3', 'transformer.blocks.12.attn.layernorm_qkv.1', 'transformer.blocks.12.attn.out_proj', 'transformer.blocks.12.ffn.1', 'transformer.blocks.12.ffn.3', 'transformer.blocks.13.attn.layernorm_qkv.1', 'transformer.blocks.13.attn.out_proj', 'transformer.blocks.13.ffn.1', 'transformer.blocks.13.ffn.3', 'transformer.blocks.14.attn.layernorm_qkv.1', 'transformer.blocks.14.attn.out_proj', 'transformer.blocks.14.ffn.1', 'transformer.blocks.14.ffn.3', 'transformer.blocks.15.attn.layernorm_qkv.1', 'transformer.blocks.15.attn.out_proj', 'transformer.blocks.15.ffn.1', 'transformer.blocks.15.ffn.3', 'transformer.blocks.16.attn.layernorm_qkv.1', 'transformer.blocks.16.attn.out_proj', 'transformer.blocks.16.ffn.1', 'transformer.blocks.16.ffn.3', 'transformer.blocks.17.attn.layernorm_qkv.1', 'transformer.blocks.17.attn.out_proj', 'transformer.blocks.17.ffn.1', 'transformer.blocks.17.ffn.3', 'transformer.blocks.18.attn.layernorm_qkv.1', 'transformer.blocks.18.attn.out_proj', 'transformer.blocks.18.ffn.1', 'transformer.blocks.18.ffn.3', 'transformer.blocks.19.attn.layernorm_qkv.1', 'transformer.blocks.19.attn.out_proj', 'transformer.blocks.19.ffn.1', 'transformer.blocks.19.ffn.3', 'transformer.blocks.20.attn.layernorm_qkv.1', 'transformer.blocks.20.attn.out_proj', 'transformer.blocks.20.ffn.1', 'transformer.blocks.20.ffn.3', 'transformer.blocks.21.attn.layernorm_qkv.1', 'transformer.blocks.21.attn.out_proj', 'transformer.blocks.21.ffn.1', 'transformer.blocks.21.ffn.3', 'transformer.blocks.22.attn.layernorm_qkv.1', 'transformer.blocks.22.attn.out_proj', 'transformer.blocks.22.ffn.1', 'transformer.blocks.22.ffn.3', 'transformer.blocks.23.attn.layernorm_qkv.1', 'transformer.blocks.23.attn.out_proj', 'transformer.blocks.23.ffn.1', 'transformer.blocks.23.ffn.3', 'transformer.blocks.24.attn.layernorm_qkv.1', 'transformer.blocks.24.attn.out_proj', 'transformer.blocks.24.ffn.1', 'transformer.blocks.24.ffn.3', 'transformer.blocks.25.attn.layernorm_qkv.1', 'transformer.blocks.25.attn.out_proj', 'transformer.blocks.25.ffn.1', 'transformer.blocks.25.ffn.3', 'transformer.blocks.26.attn.layernorm_qkv.1', 'transformer.blocks.26.attn.out_proj', 'transformer.blocks.26.ffn.1', 'transformer.blocks.26.ffn.3', 'transformer.blocks.27.attn.layernorm_qkv.1', 'transformer.blocks.27.attn.out_proj', 'transformer.blocks.27.ffn.1', 'transformer.blocks.27.ffn.3', 'transformer.blocks.28.attn.layernorm_qkv.1', 'transformer.blocks.28.attn.out_proj', 'transformer.blocks.28.ffn.1', 'transformer.blocks.28.ffn.3', 'transformer.blocks.29.attn.layernorm_qkv.1', 'transformer.blocks.29.attn.out_proj', 'transformer.blocks.29.ffn.1', 'transformer.blocks.29.ffn.3', 'transformer.blocks.30.attn.layernorm_qkv.1', 'transformer.blocks.30.attn.out_proj', 'transformer.blocks.30.ffn.1', 'transformer.blocks.30.ffn.3', 'transformer.blocks.31.attn.layernorm_qkv.1', 'transformer.blocks.31.attn.out_proj', 'transformer.blocks.31.ffn.1', 'transformer.blocks.31.ffn.3', 'transformer.blocks.32.attn.layernorm_qkv.1', 'transformer.blocks.32.attn.out_proj', 'transformer.blocks.32.ffn.1', 'transformer.blocks.32.ffn.3', 'transformer.blocks.33.attn.layernorm_qkv.1', 'transformer.blocks.33.attn.out_proj', 'transformer.blocks.33.ffn.1', 'transformer.blocks.33.ffn.3', 'transformer.blocks.34.attn.layernorm_qkv.1', 'transformer.blocks.34.attn.out_proj', 'transformer.blocks.34.ffn.1', 'transformer.blocks.34.ffn.3', 'transformer.blocks.35.attn.layernorm_qkv.1', 'transformer.blocks.35.attn.out_proj', 'transformer.blocks.35.ffn.1', 'transformer.blocks.35.ffn.3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LoRA configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=4,  # Rank of the LoRA update matrices\n",
        "    lora_alpha=32,  # Scaling factor for the LoRA update matrices\n",
        "    lora_dropout=0.05,  # Dropout probability for the LoRA update matrices\n",
        "    bias=\"none\",  # Whether to apply bias to the LoRA update matrices\n",
        "    task_type=TaskType.SEQ_CLS,  # Task type for sequence classification\n",
        "    target_modules=target_modules,  # Modules which LORA method should target and modify their weights\n",
        ")\n",
        "\n",
        "# Apply LoRA to the classification model\n",
        "model = get_peft_model(model_classification, lora_config)\n",
        "\n",
        "# Prints the number of trainable parameters in the LoRA-adapted model\n",
        "model.print_trainable_parameters()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9-L4undMsDZ",
        "outputId": "84ba6f7c-85db-4e61-99e3-4fb48589000e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 13,298,691 || all params: 598,906,438 || trainable%: 2.2205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Previous version of a custom data collator\n",
        "class CustomDataCollator:\n",
        "    def __call__(self, features):\n",
        "        # Accessing embeddings and labels from Hugging Face Dataset\n",
        "        inputs_embeds = [f['inputs_embeds'] for f in features]\n",
        "        labels = [f['labels'] for f in features]\n",
        "\n",
        "        # Convert inputs_embeds elements to PyTorch tensors if necessary\n",
        "        inputs_embeds = [torch.tensor(x) if not isinstance(x, torch.Tensor) else x for x in inputs_embeds]\n",
        "        inputs_embeds = [x.unsqueeze(0) for x in inputs_embeds] # Add sequence length dimension\n",
        "\n",
        "        # Convert the lists to tensors and create batch\n",
        "        batch = {\n",
        "            \"inputs_embeds\": torch.stack(inputs_embeds),  # Stack inputs_embeds to add batch dimension\n",
        "            \"labels\": torch.tensor(labels),\n",
        "        }\n",
        "        return batch\n",
        "\n",
        "data_collator = CustomDataCollator()"
      ],
      "metadata": {
        "id": "tZhIMNJqSvO0",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Testing the custom data collator on a small batch of embeddings to check their dimensions\n",
        "\n",
        "test_batch = [train_dataset_classification[i] for i in range(5)]\n",
        "data_collator = CustomDataCollator()\n",
        "\n",
        "# Convert inputs_embeds elements to PyTorch tensors\n",
        "for sample in test_batch:\n",
        "    sample['inputs_embeds'] = torch.tensor(sample['inputs_embeds'])\n",
        "    print(sample)\n",
        "\n",
        "collated_batch = data_collator(test_batch)\n",
        "print(collated_batch['inputs_embeds'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9G0ZNmuV2GZ",
        "outputId": "fa93bc7c-9400-4aa3-b9b9-073f2bd3c5d9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'inputs_embeds': tensor([-0.0240, -0.0435, -0.0047,  ...,  0.0146,  0.0154,  0.0215]), 'labels': 0}\n",
            "{'inputs_embeds': tensor([-0.0348, -0.0418, -0.0068,  ...,  0.0146,  0.0205,  0.0159]), 'labels': 0}\n",
            "{'inputs_embeds': tensor([-0.0559, -0.0219, -0.0123,  ...,  0.0142, -0.0040,  0.0055]), 'labels': 0}\n",
            "{'inputs_embeds': tensor([-0.0571, -0.0342, -0.0193,  ...,  0.0175,  0.0003,  0.0211]), 'labels': 0}\n",
            "{'inputs_embeds': tensor([-0.0310, -0.0395, -0.0089,  ...,  0.0115,  0.0090,  0.0215]), 'labels': 2}\n",
            "torch.Size([5, 1, 1152])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the training part\n",
        "Configure the training arguments for the `Trainer()` function, the performance metrics for the model evaluation and run the actual training part (more accurately the \"supervised\" fine-tuning)."
      ],
      "metadata": {
        "id": "CBcT_lPBfuW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Deepspeed configuration\n",
        "ds_config = {\n",
        "    \"fp16\": {\n",
        "        \"enabled\": \"auto\",  # Let DeepSpeed automatically handle FP16\n",
        "        # ... other FP16 settings\n",
        "    },\n",
        "    \"optimizer\": {\n",
        "        \"type\": \"AdamW\",\n",
        "        \"params\": {\n",
        "            \"lr\": \"auto\",  # Let DeepSpeed choose appropriate learning rate\n",
        "            # ... other optimizer settings\n",
        "        }\n",
        "    },\n",
        "    \"zero_optimization\": {\n",
        "        \"stage\": 2,  # Use ZeRO Stage 2 for memory optimization\n",
        "        \"offload_optimizer\": {\n",
        "            \"device\": \"cpu\",  # Offload optimizer states to CPU\n",
        "            \"pin_memory\": True,  # Pin optimizer states in memory\n",
        "        },\n",
        "        # ... other ZeRO settings\n",
        "    },\n",
        "    # ... other DeepSpeed settings\n",
        "}"
      ],
      "metadata": {
        "id": "53HygpZQeQ35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Huggingface Trainer arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy = \"epoch\",\n",
        "    logging_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=3e-4,\n",
        "    # effective training batch size is batch * accum\n",
        "    # we recommend an effective training batch size of 8\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=16,\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    #deepspeed= ds_config if deepspeed else None,\n",
        "    fp16 = False,\n",
        "    gradient_checkpointing=False,\n",
        ")\n",
        "\n",
        "\n",
        "# Metric definition for validation data\n",
        "def compute_metrics(eval_pred: EvalPrediction):\n",
        "    \"\"\"\n",
        "    Calculates accuracy, precision, recall, and F1 score for a 3-label classification task.\n",
        "    EvalPredictopn class is the evaluation output of the model, used to compute metrics, contains predictions (logits of the model) and labels_ids (true labels to be matched).\n",
        "\n",
        "    Args:\n",
        "        eval_pred: An EvalPrediction object containing the model's predictions and the true labels.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the calculated metrics.\n",
        "    \"\"\"\n",
        "    metric = load(\"accuracy\")\n",
        "\n",
        "    logits = eval_pred.predictions[0] if isinstance(eval_pred.predictions, tuple) else eval_pred.predictions\n",
        "    labels = eval_pred.label_ids[1] if isinstance(eval_pred.label_ids, tuple) else eval_pred.label_ids\n",
        "    predictions = logits.argmax(axis=-1)\n",
        "\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "\n",
        "# Define the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=torchdataset_my_train,\n",
        "    eval_dataset=torchdataset_my_valid,\n",
        "    data_collator=data_collator,  # the custom data collator\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the training history log\n",
        "training_history = trainer.state.log_history\n"
      ],
      "metadata": {
        "id": "CDPjkP4OPwKS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722,
          "referenced_widgets": [
            "1448f6baea844fe8b9661de310b1d066",
            "e32be594ac0f49eeb24f1b5fdbffa1ba",
            "55ccfc9b31d6422b965d1611c90504e1",
            "da34ca4c86d540d48eee3cd32ba4d58e",
            "3be98ad90599418abe56702726d9e949",
            "25b89338b6734809be541eccb2fa24a9",
            "3039658222fe446abc4e8182dd2571ce",
            "0458211af08d45e787543759b3b6a619",
            "6d2a03f544a54d4cb32774968ec9b7c3",
            "2feef36633e9474697d1a66af54f5f74",
            "848f52e9f5424af7be7eadecf538ace9"
          ]
        },
        "outputId": "689c0a0d-6910-4030-fda4-b46a99724e07"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdani-dubinsky\u001b[0m (\u001b[33mdani-dubinsky-biotax\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250225_095602-icq9qz32</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dani-dubinsky-biotax/huggingface/runs/icq9qz32' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/dani-dubinsky-biotax/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dani-dubinsky-biotax/huggingface' target=\"_blank\">https://wandb.ai/dani-dubinsky-biotax/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dani-dubinsky-biotax/huggingface/runs/icq9qz32' target=\"_blank\">https://wandb.ai/dani-dubinsky-biotax/huggingface/runs/icq9qz32</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 07:15, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.060300</td>\n",
              "      <td>0.596672</td>\n",
              "      <td>0.920000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.485700</td>\n",
              "      <td>0.513929</td>\n",
              "      <td>0.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.007600</td>\n",
              "      <td>0.436962</td>\n",
              "      <td>0.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.517056</td>\n",
              "      <td>0.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.528660</td>\n",
              "      <td>0.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.529000</td>\n",
              "      <td>0.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.526617</td>\n",
              "      <td>0.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.525900</td>\n",
              "      <td>0.960000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1448f6baea844fe8b9661de310b1d066"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=120, training_loss=0.2766960693122087, metrics={'train_runtime': 472.0146, 'train_samples_per_second': 2.119, 'train_steps_per_second': 0.254, 'total_flos': 1277971281741840.0, 'train_loss': 0.2766960693122087, 'epoch': 9.24})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot the training history with train/val results"
      ],
      "metadata": {
        "id": "T-P-oqF-mq2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get loss, val_loss, and the computed metric from history\n",
        "loss = [x['loss'] for x in training_history if 'loss' in x]\n",
        "val_loss = [x['eval_loss'] for x in training_history if 'eval_loss' in x]\n",
        "\n",
        "# Get spearman (for regression) or accuracy value (for classification)\n",
        "if [x['eval_spearmanr'] for x in training_history if 'eval_spearmanr' in x] != []:\n",
        "    metric = [x['eval_spearmanr'] for x in training_history if 'eval_spearmanr' in x]\n",
        "else:\n",
        "    metric = [x['eval_accuracy'] for x in training_history if 'eval_accuracy' in x]\n",
        "\n",
        "epochs = [x['epoch'] for x in training_history if 'loss' in x]\n",
        "\n",
        "# Create a figure with two y-axes\n",
        "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
        "ax2 = ax1.twinx()\n",
        "\n",
        "# Plot loss and val_loss on the first y-axis\n",
        "line1 = ax1.plot(epochs, loss, label='train_loss')\n",
        "line2 = ax1.plot(epochs, val_loss[0:10], label='val_loss')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "\n",
        "# Plot the computed metric on the second y-axis\n",
        "line3 = ax2.plot(epochs, metric[0:10], color='red', label='val_metric')\n",
        "ax2.set_ylabel('Metric')\n",
        "ax2.set_ylim([0, 1])\n",
        "\n",
        "# Combine the lines from both y-axes and create a single legend\n",
        "lines = line1 + line2 + line3\n",
        "labels = [line.get_label() for line in lines]\n",
        "ax1.legend(lines, labels, loc='lower left')\n",
        "\n",
        "plt.title(\"Training History\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "CUWZroYzmizF",
        "outputId": "528efa8e-9eda-49f0-fe48-bfa7ccdee3b8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Short summary of model evaluation scores\n",
        "# Evaluate the model\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Evaluation results: {eval_results}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "eaozJeHUlcmW",
        "outputId": "fcc5af5d-2bb0-4936-d8d2-4384896f81f0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results: {'eval_loss': 0.4369618594646454, 'eval_accuracy': 0.96, 'eval_runtime': 6.5183, 'eval_samples_per_second': 3.835, 'eval_steps_per_second': 0.307, 'epoch': 9.24}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Example how Accuracy metric is calculated with `evaluate` library (also from HuggingFace)\n",
        "predictions = [0, 1, 2, 0, 1]  # Model's predictions\n",
        "labels = [0, 1, 1, 0, 2]  # True labels\n",
        "metric = load(\"accuracy\")\n",
        "accuracy_score = metric.compute(predictions=predictions, references=labels)\n",
        "print(accuracy_score)"
      ],
      "metadata": {
        "id": "B8YjLWouO794",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clear GPU memory manually\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "smICDQArpn-F",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save and Load the finetuned model"
      ],
      "metadata": {
        "id": "TN94R0FBow4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model,filepath):\n",
        "    '''Saves all parameters that were changed during finetuning (\"non-frozen\" parameters)'''\n",
        "\n",
        "    # Create a dictionary to hold the non-frozen parameters\n",
        "    non_frozen_params = {}\n",
        "\n",
        "    # Iterate through all the model parameters\n",
        "    for param_name, param in model.named_parameters():\n",
        "        # If the parameter has requires_grad=True, add it to the dictionary\n",
        "        if param.requires_grad:\n",
        "            non_frozen_params[param_name] = param.detach().cpu()\n",
        "\n",
        "    # Save only the finetuned parameters\n",
        "    torch.save(non_frozen_params, filepath)\n",
        "\n",
        "\n",
        "def load_model(filepath, num_labels=1):\n",
        "    '''Creates a new instance of the original pre-trained Synthyra/ESMplusplus_large 600M model and\n",
        "    loads the finetuned weights from a file'''\n",
        "\n",
        "    # Load a new model and tokenizer\n",
        "    config = AutoConfig.from_pretrained('Synthyra/ESMplusplus_large', trust_remote_code=True, num_labels=3)\n",
        "    model_classification = AutoModelForSequenceClassification.from_pretrained('Synthyra/ESMplusplus_large', trust_remote_code=True, config=config)\n",
        "    tokenizer = model_classification.tokenizer\n",
        "\n",
        "    # Load the non-frozen parameters (the finetuned model) from the saved file\n",
        "    non_frozen_params = torch.load(filepath)\n",
        "\n",
        "    # Assign the non-frozen parameters to the corresponding parameters of the model\n",
        "    for param_name, param in model.named_parameters():\n",
        "        if param_name in non_frozen_params:\n",
        "            # .data attribute refers to the underlying tensor containing the param data, modifying it directly modifies the tensor within the model.\n",
        "            param.data = non_frozen_params[param_name].data\n",
        "\n",
        "    return tokenizer, model\n"
      ],
      "metadata": {
        "id": "lkVoBTA6oxFO"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This saves only the finetuned (non-frozen parameters) weights to a .pth file\n",
        "\n",
        "It is a 50 MB File, while the entire model would be around 2.4 GB"
      ],
      "metadata": {
        "id": "MXivLj6DpcEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(model,\"/content/drive/My Drive/LLMs_data/models_checkpoint/ESMplusplus_large_600M_finetuned_plastic_polymers_pident50_len550_nr_small_v1.pth\")"
      ],
      "metadata": {
        "id": "jbhoxesbo3n6"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load a finetuned model from file\n",
        "To load the weights again, we initialize a new pre-trained model from the pretrained checkpoint and load the LoRA weights afterwards\n",
        "\n",
        "You need to specifiy the correct num_labels!"
      ],
      "metadata": {
        "id": "EWP_mfGhqlBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer, model_reload = load_model(\"/content/drive/My Drive/LLMs_data/models_checkpoint/ESMplusplus_large_600M_finetuned_plastic_polymers_pident50_len550_nr_small_v1.pth\",\n",
        "                                     num_labels=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIU3mFvSo-Co",
        "outputId": "222a58a9-3bdf-4163-fde2-e95b3a16843e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ESMplusplusForSequenceClassification were not initialized from the model checkpoint at Synthyra/ESMplusplus_large and are newly initialized: ['classifier.0.bias', 'classifier.0.weight', 'classifier.2.bias', 'classifier.2.weight', 'classifier.3.bias', 'classifier.3.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-54-9469e1ec62f2>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  non_frozen_params = torch.load(filepath)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if the original and the reloaded models are identical by comparing their weights"
      ],
      "metadata": {
        "id": "drZ1gVVfrVQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Put both models to the same device\n",
        "model=model.to(\"cpu\")\n",
        "model_reload=model_reload.to(\"cpu\")\n",
        "\n",
        "# Iterate through the parameters of the two models and compare the data\n",
        "for param1, param2 in zip(model.parameters(), model_reload.parameters()):\n",
        "    if not torch.equal(param1.data, param2.data):\n",
        "        print(\"Models have different weights\")\n",
        "        break\n",
        "else:\n",
        "    print(\"Models have identical weights\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1kfgQyno-Ft",
        "outputId": "67d4fae9-b2c4-4767-eca4-24709ec61c85"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models have identical weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test results of the model's classification ability\n",
        "The mapping of the labels to the plastic type:\n",
        "{'PET': 0, 'PLA': 1, 'PE': 2}"
      ],
      "metadata": {
        "id": "pLVOcFz7scXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Predict the protein class (plastic degrading enzymes - PET/PE/PLA) from a set of sequences + labels (using batches)\n",
        "\n",
        "def predict_on_test_set_batch(model, test_set, tokenizer):\n",
        "    \"\"\"\n",
        "    Makes predictions on a test dataset using a loaded model.\n",
        "    Also preprocesses the sequences according to how the model was trained (remove uncommon AAs, * and pad with spaces between AAs).\n",
        "\n",
        "    Args:\n",
        "        model: The loaded model.\n",
        "        test_set: The test dataset as a pandas DataFrame with 'sequence' and 'label' columns.\n",
        "        tokenizer: The tokenizer used for the model.\n",
        "\n",
        "    Returns:\n",
        "        A list of predictions, probabilites and raw logits.\n",
        "    \"\"\"\n",
        "\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    torchdataset_test = StringLabelDatasetFromHF(test_set)\n",
        "    test_dataloader = DataLoader(torchdataset_test, batch_size=8, collate_fn=data_collator)\n",
        "\n",
        "    # Put the model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    logits = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_dataloader):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            logits += model(input_ids, attention_mask=attention_mask).logits.tolist()\n",
        "\n",
        "    probs = F.softmax(torch.tensor(logits), dim=-1)\n",
        "    predictions = np.array(logits).argmax(axis=1) # predictions = [item.argmax() for item in np.array(logits)]\n",
        "\n",
        "    return predictions, probs, logits\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fvwLrf1tsVXR"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, probs, logits = predict_on_test_set_batch(model, my_test[0:25], tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3df08a394fad46efa401087530d00e45",
            "4371f8aaef2c40009c6fdf17e1163eae",
            "81e7fd696714413c97e8b934d8255cd5",
            "d97c4976c758471995668dd1fb25bc5a",
            "e111f9155071484d9d5b4c9be08843cf",
            "5245a6a0c4554ab594c24ae344fe9e5f",
            "c148645823ba4663b99a19c799e09e79",
            "07a58255401841a89dd47e46678e7546",
            "fc7d938c4fce4d65a5495aecf483976f",
            "3acfabcb803e4623b8aef12073f6225b",
            "6f22f364bfaf42599f890d4496ac7a38"
          ]
        },
        "id": "meAyfKELtlXh",
        "outputId": "6c2b15c9-fa88-4f41-8ecf-52af5dfb6c65"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3df08a394fad46efa401087530d00e45"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)\n",
        "print(probs)\n",
        "print(logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38LXLidftldG",
        "outputId": "cefa96a8-9184-43c6-841a-bf7da85c2f4e"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 1 0 0 2 0 2 0 2 0 0 0 0 0 0 1 0 1 0 0 0 2 0]\n",
            "tensor([[9.9974e-01, 2.5752e-04, 3.8730e-13],\n",
            "        [9.9927e-01, 7.2782e-04, 6.2504e-10],\n",
            "        [9.6743e-01, 3.2570e-02, 2.0008e-11],\n",
            "        [1.7805e-05, 9.9998e-01, 9.8845e-07],\n",
            "        [9.8653e-01, 1.3472e-02, 4.8458e-11],\n",
            "        [9.9993e-01, 7.3461e-05, 6.2129e-12],\n",
            "        [2.3868e-16, 7.7371e-10, 1.0000e+00],\n",
            "        [9.9003e-01, 9.9675e-03, 4.7106e-14],\n",
            "        [2.0252e-20, 1.2549e-12, 1.0000e+00],\n",
            "        [9.9879e-01, 1.2083e-03, 1.9771e-11],\n",
            "        [1.0781e-15, 5.2448e-09, 1.0000e+00],\n",
            "        [9.9839e-01, 1.6121e-03, 7.2440e-13],\n",
            "        [7.5555e-01, 2.4445e-01, 4.3571e-10],\n",
            "        [9.9775e-01, 2.2481e-03, 1.8686e-14],\n",
            "        [9.0988e-01, 9.0121e-02, 5.8185e-12],\n",
            "        [9.8048e-01, 1.9524e-02, 8.3948e-14],\n",
            "        [9.9996e-01, 3.5878e-05, 3.7784e-14],\n",
            "        [4.6038e-05, 9.9995e-01, 6.8596e-07],\n",
            "        [9.9993e-01, 6.6848e-05, 5.9042e-13],\n",
            "        [2.2483e-05, 9.9997e-01, 7.2838e-06],\n",
            "        [9.9997e-01, 2.6361e-05, 2.7224e-13],\n",
            "        [9.9842e-01, 1.5825e-03, 7.1863e-11],\n",
            "        [7.9647e-01, 2.0353e-01, 2.2688e-09],\n",
            "        [3.2286e-19, 3.2404e-12, 1.0000e+00],\n",
            "        [9.9988e-01, 1.2004e-04, 9.3504e-13]])\n",
            "[[13.122757911682129, 4.858595371246338, -15.456550598144531], [10.414813995361328, 3.1900923252105713, -10.777655601501465], [10.533589363098145, 7.142343521118164, -14.068181991577148], [-1.6947482824325562, 9.241264343261719, -4.585846424102783], [10.19739818572998, 5.903798580169678, -13.539360046386719], [12.586309432983398, 3.0676229000091553, -13.218011856079102], [-15.478094100952148, -0.48651817440986633, 20.49329948425293], [12.702838897705078, 8.104433059692383, -17.97351837158203], [-19.31171417236328, -1.369592308998108, 26.03434181213379], [11.31057071685791, 4.593262195587158, -13.335039138793945], [-15.070252418518066, 0.3273243010044098, 19.393360137939453], [12.378499031066895, 5.949874401092529, -15.57331371307373], [8.591411590576172, 7.462957859039307, -12.682327270507812], [13.342118263244629, 7.246681213378906, -18.266611099243164], [10.309952735900879, 7.997788906097412, -15.46558952331543], [11.983856201171875, 8.067480087280273, -18.104999542236328], [14.418941497802734, 4.183591365814209, -16.487911224365234], [-0.8885723948478699, 9.097432136535645, -5.094965934753418], [13.526549339294434, 3.913530111312866, -14.631319999694824], [-2.175072431564331, 8.527657508850098, -3.30216908454895], [13.773834228515625, 3.230252265930176, -15.158220291137695], [10.744466781616211, 4.297332286834717, -12.61020565032959], [8.103961944580078, 6.7396135330200195, -11.572469711303711], [-17.85030174255371, -1.7285746335983276, 24.72675895690918], [13.016759872436523, 3.989157199859619, -14.681307792663574]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The model's classification accuracy on the test set"
      ],
      "metadata": {
        "id": "YXn8i4Z8u04D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: \", accuracy_score(my_test[0:25].label, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwrGkrR0uGsc",
        "outputId": "6f6bedee-4e2d-4a3b-e3d8-a841d7885ff4"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Process the fasta file to convert it to compatiable format with batch prediction (sequence+label)\n",
        "\n",
        "# implemented using Bio module\n",
        "def parse_fasta_to_df(fasta_path, keep_original_header=False):\n",
        "  \"\"\"Read in the fasta file, separate the headers from the sequences into df columns, and filter non-PET/PLA/PE types sequences.\"\"\"\n",
        "  seqs = {}\n",
        "  for record in SeqIO.parse(fasta_path, \"fasta\"):\n",
        "      seqs[record.description] = str(record.seq)\n",
        "  print(f'Read {len(seqs)} sequences')\n",
        "\n",
        "  # create a dataframe from the sequences dict\n",
        "  proteins_df = pd.DataFrame(data={'seq_id': seqs.keys(), 'sequence': seqs.values()}, columns=['seq_id', 'sequence'])\n",
        "\n",
        "  def _filter_plastic_types(value):\n",
        "    \"\"\"Filter out plastic types from a seq_id column string using set intersection (&) operation.\n",
        "    This will keep only allowed types (PET, PLA, PE)\"\"\"\n",
        "    extracted = {value.split(\"|\")[0]}\n",
        "    allowed = {\"PET\", \"PLA\", \"PE\"}  # Allowed values\n",
        "    filtered = extracted & allowed  # Keep only allowed values\n",
        "\n",
        "    if len(filtered) == 1:  # Keep only rows with exactly 1 valid entry\n",
        "        return next(iter(filtered))  # Extract the single value, preferred way to fetch a single element from an iterable\n",
        "    return None  # Drop rows with multiple or zero values\n",
        "\n",
        "  if keep_original_header:\n",
        "    proteins_df[\"original header\"] = proteins_df[\"seq_id\"]\n",
        "  # Apply function and drop rows with None (filtered out)\n",
        "  proteins_df[\"seq_id\"] = proteins_df[\"seq_id\"].apply(_filter_plastic_types)\n",
        "  # Remove rows that were filtered out\n",
        "  proteins_df = proteins_df.dropna().reset_index(drop=True)\n",
        "  proteins_df.rename(columns={'seq_id': 'label'}, inplace=True)\n",
        "  # convert the target polymers titles to integers\n",
        "  proteins_df['label'] = proteins_df['label'].map({'PET': 0, 'PLA': 1, 'PE': 2})\n",
        "\n",
        "  print(f'Kept {proteins_df.shape[0]} sequences')\n",
        "\n",
        "  return proteins_df\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "g5Og6nfGt7LY"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_seqs_from_db_path = \"/content/drive/My Drive/LLMs_data/input_seq/Plastic_degrading_enzymes_PE_PET_PLA_PVA_targetDB_f.fasta\"\n",
        "input_seqs_from_db = parse_fasta_to_df(input_seqs_from_db_path)\n",
        "input_seqs_from_db.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "VsLMz9HHvJ95",
        "outputId": "54d0102a-63f2-454b-be60-843bdedadd6e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 200 sequences\n",
            "Kept 175 sequences\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                           sequence\n",
              "0      0  MKRKIIRGAMALFILLTMVITQSISVSAAASKFVTSVNTTSKVVAL...\n",
              "1      0  MKQSKWYAFLSGAVLLTGIAVYGLWIGYQDIVNPPERTLSVSEDER...\n",
              "2      0  MRKETAWFVGGAAIAAATAAGASVWSQYGSLVRWQEPELPIQPTTR...\n",
              "3      0  MLHYKTYTISDDHPWVIFIHGAGGSLSHWYRQLRPFRKKYNVLLVD...\n",
              "4      0  MMGYITAHDGTNLYVEDVGFGEPIVFLHGWPANNNMFEYQKNALVE...\n",
              "5      2  MQTQDQRLLIVDDDEMFCHVLSRALTRRGFEVQVAHDADQAMTLIT...\n",
              "6      2  MPPFRSSRWLSGGHVQTLYSPLWRASPQLQRRRERMTLQDGDFIDL...\n",
              "7      2  MVPTTVDFDTLCPEPIFQDRWVATPRGRVFTRTWETSHLRSDVPIV...\n",
              "8      2  MFRFHIVSALLTLFIAVPSQAHDVGQREIKISGAEPGRNLEVSVWY...\n",
              "9      2  MIRNATAVSVDQHELAATVISPDTTIPGVLFLHGWAGSQERDIERA..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a42e0dc-83b3-4ad9-b9e1-cea0d0c2943c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>MKRKIIRGAMALFILLTMVITQSISVSAAASKFVTSVNTTSKVVAL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>MKQSKWYAFLSGAVLLTGIAVYGLWIGYQDIVNPPERTLSVSEDER...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>MRKETAWFVGGAAIAAATAAGASVWSQYGSLVRWQEPELPIQPTTR...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>MLHYKTYTISDDHPWVIFIHGAGGSLSHWYRQLRPFRKKYNVLLVD...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>MMGYITAHDGTNLYVEDVGFGEPIVFLHGWPANNNMFEYQKNALVE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>MQTQDQRLLIVDDDEMFCHVLSRALTRRGFEVQVAHDADQAMTLIT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2</td>\n",
              "      <td>MPPFRSSRWLSGGHVQTLYSPLWRASPQLQRRRERMTLQDGDFIDL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2</td>\n",
              "      <td>MVPTTVDFDTLCPEPIFQDRWVATPRGRVFTRTWETSHLRSDVPIV...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>MFRFHIVSALLTLFIAVPSQAHDVGQREIKISGAEPGRNLEVSVWY...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2</td>\n",
              "      <td>MIRNATAVSVDQHELAATVISPDTTIPGVLFLHGWAGSQERDIERA...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a42e0dc-83b3-4ad9-b9e1-cea0d0c2943c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4a42e0dc-83b3-4ad9-b9e1-cea0d0c2943c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4a42e0dc-83b3-4ad9-b9e1-cea0d0c2943c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3c5f4d46-007f-4848-8546-295acdb864b6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3c5f4d46-007f-4848-8546-295acdb864b6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3c5f4d46-007f-4848-8546-295acdb864b6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "input_seqs_from_db",
              "summary": "{\n  \"name\": \"input_seqs_from_db\",\n  \"rows\": 175,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 142,\n        \"samples\": [\n          \"MKFSIISTLLAATASALPAGQDAAALEARQLGGSITRNDLANGNSGSCPGVIFIYARGSTESGNLGTLGPRVASKLEAKYGKNGVWIQGVGGAYRATLGDNALPRGTSSAAIREMLGHFSDANQKCPDAVLIAGGYSQGAALAAASVTDVDAGIREKIAGVVLFGYTKNLQNRGKIPSYPEDRTKVFCNTGDLVCTGSLIVAAPHLAYQSAASGAAPEFLIQKADAAGAA\",\n          \"MNFPRASRLMQAAVLGGLMAVSAAATAQTNPYARGPNPTAASLEASAGPFTVRSFTVSRPSGYGAGTVYYPTNAGGTVGAIAIVPGYTARQSSIKWWGPRLASHGFVVITIDTNSTLDQPSSRSSQQMAALRQVASLNGTSSSPIYGKVDTARMGVMGWSMGGGGSLISAANNPSLKAAAPQAPWDSSTNFSSVTVPTLIFACENDSIAPVNSSALPIYDSMSRNAKQFLEINGGSHSCANSGNSNQALIGKKGVAWMKRFMDNDTRYSTFACENPNSTRVSDFRTANCS\",\n          \"MANPYERGPNPTESMLEARSGPFSVSEERASRLGADGFGGGTIYYPRENNTYGAIAISPGYTGTQSSIAWLGERIASHGFVVIAIDTNTTLDQPDSRARQLNAALDYMLTDASSSVRNRIDASRLAVMGHSMGGGGTLRLASQRPDLKAAIPLTPWHLNKSWRDITVPTLIIGADLDTIAPVSSHSEPFYNSIPSSTDKAYLELNNATHFAPNITNKTIGMYSVAWLKRFVDEDTRYTQFLCPGPRTGLLSDVDEYRSTCPFLEHHHHHH\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The model's classification accuracy on an independent set (Plastic degrading proteins DB)\n",
        "Let's take all (or most) of the sequences in the Plastic degrading enzymes DB and try the model's prediction ability on them.\n",
        "\n",
        "It will give an additional info about its classification ability in a more generalized sense, as these sequences were manually curated and validated, while all the train-val-test dataset sequences are directly from metagenomic data and their labels were assigned by homology search (in a sense these labels are predicted)."
      ],
      "metadata": {
        "id": "-ZuZy_-a0Ow3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, probs, logits = predict_on_test_set_batch(model, input_seqs_from_db, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c649d54d77554ca7a862243915cff823",
            "76625b4020f44758b00c4402f0323db2",
            "30b38360b1ed4c99b7bf37e89c6c74fe",
            "351c4c4fcc5d423ba1902ab620b0b9f5",
            "e0cdd2463bc3400f8c28a578d5905828",
            "318c3e3a29c14390afa253c67a6873b6",
            "93de9f6115f5478c969bcf5aab3767a5",
            "4f26474b04ca430ebe6cca12176805bd",
            "cbd0914a0dff483ebb173f3e513693a7",
            "28660e0f8e304486a87efd186b430e83",
            "76b53cd9b0f344afb8eb5c3abda183d7"
          ]
        },
        "id": "2KvwVjqb0OXo",
        "outputId": "f774c6e8-0191-476b-fa1b-b14fe1a42718"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/22 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c649d54d77554ca7a862243915cff823"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: \", accuracy_score(input_seqs_from_db.label, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9qhbbI9049K",
        "outputId": "4fb758e2-1e26-4e7f-a3ae-3816a06432b9"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.8285714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zGin1zte1Wer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "j3NrYSal1XDO"
      }
    }
  ]
}